import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import io
from scipy.optimize import minimize
from sklearn.linear_model import LinearRegression

st.set_page_config(page_title="ØªØ­Ù„ÛŒÙ„ Ù¾Ø±ØªÙÙˆ Ø¨Ø§ Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ Ùˆ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ú©Ù„Ø§Ø³ÛŒÚ©", layout="wide")
st.title("ğŸ“Š Ø§Ø¨Ø²Ø§Ø± ØªØ­Ù„ÛŒÙ„ Ù¾Ø±ØªÙÙˆ Ø¨Ø§ Ø±ÙˆØ´ Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ Ùˆ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ú©Ù„Ø§Ø³ÛŒÚ©")

# ØªØ§Ø¨Ø¹ Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ù…Ù‚Ø§ÙˆÙ… Ø¨Ø§ ØªØ´Ø®ÛŒØµ Ø¬Ø¯Ø§Ú©Ù†Ù†Ø¯Ù‡ (Ø­ØªÛŒ ØªØ¨) Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØµØ­ÛŒØ­ Ù‚ÛŒÙ…Øª
def smart_read_file(file):
    try:
        content = file.read()
        try:
            content = content.decode("utf-8")
        except Exception:
            content = content.decode("latin1")
        sample = "\n".join(content.splitlines()[:3])
        if "\t" in sample:
            sep = "\t"
        elif ";" in sample:
            sep = ";"
        elif "," in sample and sample.count(",") > sample.count("\t") + sample.count(";"):
            sep = ","
        elif "|" in sample:
            sep = "|"
        else:
            sep = "\t"  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù„ÛŒ
        df = pd.read_csv(io.StringIO(content), sep=sep)
        col_date = [col for col in df.columns if 'date' in col.lower() or 'ØªØ§Ø±ÛŒØ®' in col.lower()]
        col_price = [col for col in df.columns if 'price' in col.lower() or 'Ù‚ÛŒÙ…Øª' in col.lower()]
        if not col_date or not col_price:
            st.error("Ø³ØªÙˆÙ† ØªØ§Ø±ÛŒØ® ÛŒØ§ Ù‚ÛŒÙ…Øª ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù†Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Ø´Ø§Ù…Ù„ 'Date' ÛŒØ§ 'ØªØ§Ø±ÛŒØ®' Ùˆ 'Price' ÛŒØ§ 'Ù‚ÛŒÙ…Øª' Ø¨Ø§Ø´Ø¯.")
            return None
        df = df[[col_date[0], col_price[0]]].copy()
        df.columns = ['Date', 'Price']
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce', dayfirst=False)
        df['Price'] = (
            df['Price'].astype(str)
                .str.replace('Ù¬', '', regex=False)
                .str.replace(',', '', regex=False)
                .str.replace(' ', '', regex=False)
                .str.replace(r'[^\d\.\-]', '', regex=True)
        )
        df['Price'] = pd.to_numeric(df['Price'], errors='coerce')
        df = df.dropna(subset=['Date', 'Price'])
        df = df.sort_values('Date')
        if len(df) < 3:
            return None
        return df
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„: {e}")
        return None

def get_gmv_weights(cov_matrix):
    n = cov_matrix.shape[0]
    args = (cov_matrix,)
    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1.0})
    bounds = tuple((0, 1) for _ in range(n))
    result = minimize(lambda w, cov: w.T @ cov @ w, n*[1./n], args=args, method='SLSQP', bounds=bounds, constraints=constraints)
    return result.x

def get_max_sharpe_weights(mean_returns, cov_matrix, rf=0):
    n = len(mean_returns)
    def neg_sharpe(w, mean, cov, rf):
        port_return = np.dot(w, mean)
        port_vol = np.sqrt(np.dot(w.T, np.dot(cov, w)))
        return -(port_return - rf) / port_vol
    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1.0})
    bounds = tuple((0, 1) for _ in range(n))
    result = minimize(neg_sharpe, n*[1./n], args=(mean_returns, cov_matrix, rf), method='SLSQP', bounds=bounds, constraints=constraints)
    return result.x

def regression_forecast(prices, periods_ahead=1):
    prices = prices.dropna()
    if len(prices) < 10:
        return np.nan
    X = np.arange(len(prices)).reshape(-1, 1)
    y = prices.values
    model = LinearRegression().fit(X, y)
    pred = model.predict([[len(prices) + periods_ahead - 1]])
    return float(pred)

st.sidebar.header("ğŸ“‚ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ (CSV/TXT - Ø¬Ø¯Ø§Ú©Ù†Ù†Ø¯Ù‡ Ù‡ÙˆØ´Ù…Ù†Ø¯)")
uploaded_files = st.sidebar.file_uploader(
    "Ú†Ù†Ø¯ ÙØ§ÛŒÙ„ CSV ÛŒØ§ TXT Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ (Ù‡Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ ÛŒÚ© ÙØ§ÛŒÙ„ Ø¬Ø¯Ø§)", type=['csv', 'txt'], accept_multiple_files=True, key="uploader"
)

period = st.sidebar.selectbox("Ø¨Ø§Ø²Ù‡ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø¯Ù‡", ['Ù…Ø§Ù‡Ø§Ù†Ù‡', 'Ø³Ù‡â€ŒÙ…Ø§Ù‡Ù‡', 'Ù‡ÙØªÚ¯ÛŒ'])
resample_rule = {'Ù…Ø§Ù‡Ø§Ù†Ù‡': 'M', 'Ø³Ù‡â€ŒÙ…Ø§Ù‡Ù‡': 'Q', 'Ù‡ÙØªÚ¯ÛŒ': 'W'}[period]
annual_factor = {'Ù…Ø§Ù‡Ø§Ù†Ù‡': 12, 'Ø³Ù‡â€ŒÙ…Ø§Ù‡Ù‡': 4, 'Ù‡ÙØªÚ¯ÛŒ': 52}[period]

if uploaded_files:
    prices_df = pd.DataFrame()
    asset_names = []

    for file in uploaded_files:
        df = smart_read_file(file)
        if df is None:
            st.warning(f"ÙØ§ÛŒÙ„ {file.name} Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ³Øª ÛŒØ§ Ú©Ù…ØªØ± Ø§Ø² Û³ Ø³Ø·Ø± Ø¯ÛŒØªØ§ Ø¯Ø§Ø±Ø¯.")
            continue
        name = file.name.split('.')[0]
        df = df[['Date', 'Price']].set_index('Date')
        df.columns = [name]
        prices_df = df if prices_df.empty else prices_df.join(df, how='inner')
        asset_names.append(name)

    if prices_df.empty:
        st.error("âŒ Ø¯Ø§Ø¯Ù‡â€ŒÛŒ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        st.stop()

    st.subheader("ğŸ§ª Ù¾ÛŒØ´â€ŒÙ†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§")
    st.dataframe(prices_df.tail())

    resampled_prices = prices_df.resample(resample_rule).last().dropna()
    returns = resampled_prices.pct_change().dropna()
    mean_returns = returns.mean() * annual_factor
    cov_matrix = returns.cov() * annual_factor

    with st.expander("ğŸ“ˆ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ú©Ù„Ø§Ø³ÛŒÚ© (GMV, Sharpe, Ø±Ú¯Ø±Ø³ÛŒÙˆÙ†)"):
        gmv_weights = get_gmv_weights(cov_matrix)
        gmv_ret = np.dot(gmv_weights, mean_returns)
        gmv_risk = np.sqrt(np.dot(gmv_weights.T, np.dot(cov_matrix, gmv_weights)))
        st.markdown("#### ğŸ“˜ Ø­Ø¯Ø§Ù‚Ù„ ÙˆØ§Ø±ÛŒØ§Ù†Ø³ Ø¬Ù‡Ø§Ù†ÛŒ (GMV)")
        st.markdown(f'''
        <div dir="rtl" style="text-align: right">
        Ø¨Ø§Ø²Ø¯Ù‡ Ø³Ø§Ù„Ø§Ù†Ù‡: {gmv_ret:.2%} <br>
        Ø±ÛŒØ³Ú© Ø³Ø§Ù„Ø§Ù†Ù‡: {gmv_risk:.2%} <br>
        {'<br>'.join([f"ğŸ”¹ <b>{asset_names[i]}</b>: {w*100:.2f}%" for i, w in enumerate(gmv_weights)])}
        </div>
        ''', unsafe_allow_html=True)
        fig_gmv = go.Figure(data=[go.Pie(labels=asset_names, values=gmv_weights*100, hole=0.5)])
        fig_gmv.update_layout(title="ØªØ±Ú©ÛŒØ¨ ÙˆØ²Ù†ÛŒ Ù¾Ø±ØªÙÙˆ GMV")
        st.plotly_chart(fig_gmv, use_container_width=True)

        ms_weights = get_max_sharpe_weights(mean_returns, cov_matrix)
        ms_ret = np.dot(ms_weights, mean_returns)
        ms_risk = np.sqrt(np.dot(ms_weights.T, np.dot(cov_matrix, ms_weights)))
        ms_sharpe = (ms_ret) / ms_risk
        st.markdown("#### ğŸ“™ Ù¾Ø±ØªÙÙˆ Ø¨Ø§ Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† Ù†Ø±Ø® Ø´Ø§Ø±Ù¾ (Maximum Sharpe Ratio)")
        st.markdown(f'''
        <div dir="rtl" style="text-align: right">
        Ø¨Ø§Ø²Ø¯Ù‡ Ø³Ø§Ù„Ø§Ù†Ù‡: {ms_ret:.2%} <br>
        Ø±ÛŒØ³Ú© Ø³Ø§Ù„Ø§Ù†Ù‡: {ms_risk:.2%} <br>
        Ù†Ø³Ø¨Øª Ø´Ø§Ø±Ù¾: {ms_sharpe:.2f} <br>
        {'<br>'.join([f"ğŸ”¸ <b>{asset_names[i]}</b>: {w*100:.2f}%" for i, w in enumerate(ms_weights)])}
        </div>
        ''', unsafe_allow_html=True)
        fig_ms = go.Figure(data=[go.Pie(labels=asset_names, values=ms_weights*100, hole=0.5)])
        fig_ms.update_layout(title="ØªØ±Ú©ÛŒØ¨ ÙˆØ²Ù†ÛŒ Ù¾Ø±ØªÙÙˆ Sharpe")
        st.plotly_chart(fig_ms, use_container_width=True)

        st.markdown("#### ğŸ“— Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‚ÛŒÙ…Øª Ø¢ÛŒÙ†Ø¯Ù‡ Ø¨Ø§ Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† (ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†)")
        reg_rows = []
        for name in asset_names:
            last_price = resampled_prices[name].dropna()
            reg_pred = regression_forecast(last_price, periods_ahead=1)
            delta = reg_pred - last_price.iloc[-1] if not np.isnan(reg_pred) else np.nan
            reg_rows.append({
                "Ø¯Ø§Ø±Ø§ÛŒÛŒ": name,
                "Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ": last_price.iloc[-1],
                "Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø§Ù‡ Ø¨Ø¹Ø¯": reg_pred,
                "ØªØºÛŒÛŒØ± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ": delta
            })
        reg_df = pd.DataFrame(reg_rows)
        st.dataframe(reg_df.set_index("Ø¯Ø§Ø±Ø§ÛŒÛŒ"), use_container_width=True)

else:
    st.warning("âš ï¸ Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSV ÛŒØ§ TXT Ø¨Ø§ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Date Ùˆ Price (ÛŒØ§ ØªØ§Ø±ÛŒØ® Ùˆ Ù‚ÛŒÙ…Øª) Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ (Ù‡Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ ÛŒÚ© ÙØ§ÛŒÙ„ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡).")
