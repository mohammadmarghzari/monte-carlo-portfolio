import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import yfinance as yf
import base64

# =========================
# 1. Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ÛŒ/Ø¢Ù¾Ù„ÙˆØ¯ÛŒ Ùˆ Ø¨ÛŒÙ…Ù‡ Ø¯Ø± session_state
# =========================
if "downloaded_dfs" not in st.session_state:
    st.session_state["downloaded_dfs"] = []
if "uploaded_dfs" not in st.session_state:
    st.session_state["uploaded_dfs"] = []
if "insured_assets" not in st.session_state:
    st.session_state["insured_assets"] = {}

# =========================
# 2. ØªØ§Ø¨Ø¹ Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ csv Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ price/date
# =========================
def read_csv_file(file):
    try:
        file.seek(0)
        df_try = pd.read_csv(file)
        cols_lower = [str(c).strip().lower() for c in df_try.columns]
        if any(x in cols_lower for x in ['date']):
            df = df_try.copy()
        else:
            file.seek(0)
            df = pd.read_csv(file, header=None)
            header_idx = None
            for i in range(min(5, len(df))):
                row = [str(x).strip().lower() for x in df.iloc[i].tolist()]
                if any('date' == x for x in row):
                    header_idx = i
                    break
            if header_idx is None:
                raise Exception("Ø³Ø·Ø± Ø¹Ù†ÙˆØ§Ù† Ù…Ù†Ø§Ø³Ø¨ (Ø´Ø§Ù…Ù„ date) ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            header_row = df.iloc[header_idx].tolist()
            df = df.iloc[header_idx+1:].reset_index(drop=True)
            df.columns = header_row

        date_col = [c for c in df.columns if str(c).strip().lower() == 'date']
        if not date_col:
            raise Exception("Ø³ØªÙˆÙ† ØªØ§Ø±ÛŒØ® Ø¨Ø§ Ù†Ø§Ù… 'Date' ÛŒØ§ Ù…Ø´Ø§Ø¨Ù‡ Ø¢Ù† ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        date_col = date_col[0]
        price_candidates = [c for c in df.columns if str(c).strip().lower() in ['price', 'close', 'adj close', 'open']]
        if not price_candidates:
            price_candidates = [c for c in df.columns if c != date_col]
        if not price_candidates:
            raise Exception("Ø³ØªÙˆÙ† Ù‚ÛŒÙ…Øª Ù…Ù†Ø§Ø³Ø¨ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        price_col = price_candidates[0]
        df = df[[date_col, price_col]].dropna()
        if df.empty:
            raise Exception("Ù¾Ø³ Ø§Ø² Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù„ÛŒØŒ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø§Ù‚ÛŒ Ù†Ù…Ø§Ù†Ø¯.")

        df = df.rename(columns={date_col: "Date", price_col: "Price"})
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
        df['Price'] = pd.to_numeric(df['Price'], errors='coerce')
        df = df.dropna(subset=['Date', 'Price'])
        if df.empty:
            raise Exception("Ù¾Ø³ Ø§Ø² ØªØ¨Ø¯ÛŒÙ„ Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡ØŒ Ø¯Ø§Ø¯Ù‡ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø§Ù‚ÛŒ Ù†Ù…Ø§Ù†Ø¯.")
        return df
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ {file.name}: {e}")
        return None

# =========================
# 3. Ù„ÛŒÙ†Ú© Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… Ø¨Ù‡ csv
# =========================
def download_link(df, filename):
    csv = df.reset_index(drop=True).to_csv(index=False).encode()
    b64 = base64.b64encode(csv).decode()
    return f'<a href="data:file/csv;base64,{b64}" download="{filename}">â¬‡ï¸ Ø¯Ø±ÛŒØ§ÙØª ÙØ§ÛŒÙ„ CSV</a>'

# =========================
# 4. ØªØ¨Ø¯ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ ÛŒØ§Ù‡Ùˆ Ø¨Ù‡ ÙØ±Ù…Øª price/date
# =========================
def get_price_dataframe_from_yf(data, t):
    if isinstance(data.columns, pd.MultiIndex):
        if t in data.columns.levels[0]:
            df_t = data[t].reset_index()
            price_col = None
            for col in ['Close', 'Adj Close', 'Open']:
                if col in df_t.columns:
                    price_col = col
                    break
            if price_col is None:
                return None, f"Ù‡ÛŒÚ† ÛŒÚ© Ø§Ø² Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª (Close, Adj Close, Open) Ø¨Ø±Ø§ÛŒ {t} Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯."
            df = df_t[['Date', price_col]].rename(columns={price_col: 'Price'})
            return df, None
        else:
            return None, f"Ù†Ù…Ø§Ø¯ {t} Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØªÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯."
    else:
        if 'Date' not in data.columns:
            data = data.reset_index()
        price_col = None
        for col in ['Close', 'Adj Close', 'Open']:
            if col in data.columns:
                price_col = col
                break
        if price_col is None:
            return None, f"Ù‡ÛŒÚ† ÛŒÚ© Ø§Ø² Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª (Close, Adj Close, Open) Ø¨Ø±Ø§ÛŒ {t} Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯."
        df = data[['Date', price_col]].rename(columns={price_col: 'Price'})
        return df, None

# =========================
# 5. Ù…Ø­Ø§Ø³Ø¨Ù‡ Max Drawdown Ù¾Ø±ØªÙÙˆÛŒ
# =========================
def calculate_max_drawdown(prices: pd.Series) -> float:
    roll_max = prices.cummax()
    drawdown = (prices - roll_max) / roll_max
    max_dd = drawdown.min()
    return max_dd

# =========================
# 6. Ù†Ù…Ø§ÛŒØ´ Ø¨Ø§Ø²Ø¯Ù‡ Ùˆ Ø±ÛŒØ³Ú© Ù¾Ø±ØªÙÙˆÛŒ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
# =========================
def show_periodic_risk_return(resampled_prices, weights, label):
    pf_prices = (resampled_prices * weights).sum(axis=1)
    pf_returns = pf_prices.pct_change().dropna()
    ann_factor = 12 if resampled_prices.index.freqstr and resampled_prices.index.freqstr.upper().startswith('M') else 52
    mean_ann = pf_returns.mean() * ann_factor
    risk_ann = pf_returns.std() * (ann_factor ** 0.5)
    pf_prices_monthly = pf_prices.resample('M').last().dropna()
    pf_returns_monthly = pf_prices_monthly.pct_change().dropna()
    mean_month = pf_returns_monthly.mean()
    risk_month = pf_returns_monthly.std()
    pf_prices_weekly = pf_prices.resample('W').last().dropna()
    pf_returns_weekly = pf_prices_weekly.pct_change().dropna()
    mean_week = pf_returns_weekly.mean()
    risk_week = pf_returns_weekly.std()
    st.markdown(f"#### ğŸ“Š {label}")
    st.markdown(f"""<div dir="rtl" style="text-align:right">
    <b>Ø³Ø§Ù„Ø§Ù†Ù‡:</b> Ø¨Ø§Ø²Ø¯Ù‡: {mean_ann:.2%} | Ø±ÛŒØ³Ú©: {risk_ann:.2%}<br>
    <b>Ù…Ø§Ù‡Ø§Ù†Ù‡:</b> Ø¨Ø§Ø²Ø¯Ù‡: {mean_month:.2%} | Ø±ÛŒØ³Ú©: {risk_month:.2%}<br>
    <b>Ù‡ÙØªÚ¯ÛŒ:</b> Ø¨Ø§Ø²Ø¯Ù‡: {mean_week:.2%} | Ø±ÛŒØ³Ú©: {risk_week:.2%}
    </div>
    """, unsafe_allow_html=True)

# =========================
# 7. Efficient Frontier Ø¨Ø§ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ÙˆØ²Ù†
# =========================
def efficient_frontier(mean_returns, cov_matrix, annual_factor, points=200, min_weights=None, max_weights=None):
    num_assets = len(mean_returns)
    results = np.zeros((3, points))
    weight_record = []
    for i in range(points):
        while True:
            weights = np.random.dirichlet(np.ones(num_assets), size=1)[0]
            if min_weights is not None:
                weights = np.maximum(weights, min_weights)
            if max_weights is not None:
                weights = np.minimum(weights, max_weights)
            weights /= np.sum(weights)
            if (min_weights is None or np.all(weights >= min_weights)) and (max_weights is None or np.all(weights <= max_weights)):
                break
        port_return = np.dot(weights, mean_returns)
        port_std = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
        results[0, i] = port_std
        results[1, i] = port_return
        results[2, i] = (port_return) / port_std if port_std > 0 else 0
        weight_record.append(weights)
    return results, np.array(weight_record)

# =========================
# 8. ØªÙˆØ¶ÛŒØ­Ø§Øª Ø§Ø¨Ø²Ø§Ø± (Ø±Ø§Ù‡Ù†Ù…Ø§)
# =========================
st.markdown("""
<div dir="rtl" style="text-align: right;">
<h3>Ø§Ø¨Ø²Ø§Ø± ØªØ­Ù„ÛŒÙ„ Ù¾Ø±ØªÙÙˆ: ØªÙˆØ¶ÛŒØ­Ø§Øª Ú©Ù„ÛŒ</h3>
Ø§ÛŒÙ† Ø§Ø¨Ø²Ø§Ø± Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªØ±Ú©ÛŒØ¨ Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ÛŒ ÛŒÚ© Ù¾Ø±ØªÙÙˆ (Portfolio) Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„ÙˆØŒ Ø¨ÛŒÙ…Ù‡ Ùˆ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´ÛŒ Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª.
</div>
""", unsafe_allow_html=True)

# ========== Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒØŒ ØªÙ†Ø¸ÛŒÙ…Ø§ØªØŒ Ø¨ÛŒÙ…Ù‡ Ùˆ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ÙˆØ²Ù† ==========
st.sidebar.header("ğŸ“‚ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ (CSV)")
uploaded_files = st.sidebar.file_uploader(
    "Ú†Ù†Ø¯ ÙØ§ÛŒÙ„ CSV Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ (Ù‡Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ ÛŒÚ© ÙØ§ÛŒÙ„)", type=['csv'], accept_multiple_files=True, key="uploader"
)
if st.session_state["downloaded_dfs"]:
    st.sidebar.markdown("<b>Ø­Ø°Ù Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡:</b>", unsafe_allow_html=True)
    for idx, (t, df) in enumerate(st.session_state["downloaded_dfs"]):
        col1, col2 = st.sidebar.columns([3, 1])
        with col1:
            st.markdown(f"<div dir='rtl' style='text-align: right; font-size: 14px'>{t}</div>", unsafe_allow_html=True)
        with col2:
            if st.button("âŒ", key=f"delete_dl_{t}_{idx}"):
                st.session_state["downloaded_dfs"].pop(idx)
                st.experimental_rerun()
if st.session_state["uploaded_dfs"]:
    st.sidebar.markdown("<b>Ø­Ø°Ù Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡:</b>", unsafe_allow_html=True)
    for idx, (t, df) in enumerate(st.session_state["uploaded_dfs"]):
        col1, col2 = st.sidebar.columns([3, 1])
        with col1:
            st.markdown(f"<div dir='rtl' style='text-align: right; font-size: 14px'>{t}</div>", unsafe_allow_html=True)
        with col2:
            if st.button("âŒ", key=f"delete_up_{t}_{idx}"):
                st.session_state["uploaded_dfs"].pop(idx)
                st.experimental_rerun()

period = st.sidebar.selectbox("Ø¨Ø§Ø²Ù‡ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø¯Ù‡", ['Ù…Ø§Ù‡Ø§Ù†Ù‡', 'Ø³Ù‡â€ŒÙ…Ø§Ù‡Ù‡', 'Ø´Ø´â€ŒÙ…Ø§Ù‡Ù‡'])
resample_rule = {'Ù…Ø§Ù‡Ø§Ù†Ù‡': 'M', 'Ø³Ù‡â€ŒÙ…Ø§Ù‡Ù‡': 'Q', 'Ø´Ø´â€ŒÙ…Ø§Ù‡Ù‡': '2Q'}[period]
annual_factor = {'Ù…Ø§Ù‡Ø§Ù†Ù‡': 12, 'Ø³Ù‡â€ŒÙ…Ø§Ù‡Ù‡': 4, 'Ø´Ø´â€ŒÙ…Ø§Ù‡Ù‡': 2}[period]
user_risk = st.sidebar.slider("Ø±ÛŒØ³Ú© Ù‡Ø¯Ù Ù¾Ø±ØªÙÙˆ (Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÛŒØ§Ø± Ø³Ø§Ù„Ø§Ù†Ù‡)", 0.01, 1.0, 0.25, 0.01)
cvar_alpha = st.sidebar.slider("Ø³Ø·Ø­ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† CVaR", 0.80, 0.99, 0.95, 0.01)
st.sidebar.markdown("<hr/>", unsafe_allow_html=True)
rf_rate = st.sidebar.number_input("Ù†Ø±Ø® Ø¨Ø§Ø²Ø¯Ù‡ Ø³Ø§Ù„Ø§Ù†Ù‡ Ø¯Ø§Ø±Ø§ÛŒÛŒ Ø¨Ø¯ÙˆÙ† Ø±ÛŒØ³Ú© (Ø³Ù¾Ø±Ø¯Ù‡/Ø§ÙˆØ±Ø§Ù‚ØŒ Ø¯Ø±ØµØ¯)", 0.0, 100.0, 20.0, 0.1) / 100

with st.sidebar.expander("ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø§Ø² Yahoo Finance"):
    st.markdown("""
    <div dir="rtl" style="text-align: right;">
    <b>Ø±Ø§Ù‡Ù†Ù…Ø§:</b>
    <br>Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø±Ø§ Ø¨Ø§ Ú©Ø§Ù…Ø§ Ùˆ Ø¨Ø¯ÙˆÙ† ÙØ§ØµÙ„Ù‡ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ (Ù…Ø«Ø§Ù„: <span style="direction:ltr;display:inline-block">BTC-USD,AAPL,ETH-USD</span>)
    </div>
    """, unsafe_allow_html=True)
    tickers_input = st.text_input("Ù†Ù…Ø§Ø¯ Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ (Ø¨Ø§ Ú©Ø§Ù…Ø§ Ùˆ Ø¨Ø¯ÙˆÙ† ÙØ§ØµÙ„Ù‡)")
    start = st.date_input("ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹", value=pd.to_datetime("2023-01-01"))
    end = st.date_input("ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†", value=pd.to_datetime("today"))
    download_btn = st.button("Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø¢Ù†Ù„Ø§ÛŒÙ†")
if download_btn and tickers_input.strip():
    tickers = [t.strip() for t in tickers_input.strip().split(",") if t.strip()]
    try:
        data = yf.download(tickers, start=start, end=end, progress=False, group_by='ticker', auto_adjust=True)
        if data.empty:
            st.error("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯!")
        else:
            new_downloaded = []
            for t in tickers:
                df, err = get_price_dataframe_from_yf(data, t)
                if df is not None:
                    df['Date'] = pd.to_datetime(df['Date'])
                    new_downloaded.append((t, df))
                    st.success(f"Ø¯Ø§Ø¯Ù‡ {t} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯.")
                    st.markdown(download_link(df, f"{t}_historical.csv"), unsafe_allow_html=True)
                else:
                    st.error(f"{err}")
            st.session_state["downloaded_dfs"].extend(new_downloaded)
    except Exception as ex:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡: {ex}")

if uploaded_files:
    for file in uploaded_files:
        if not hasattr(file, "uploaded_in_session") or not file.uploaded_in_session:
            df = read_csv_file(file)
            if df is not None:
                st.session_state["uploaded_dfs"].append((file.name.split('.')[0], df))
            file.uploaded_in_session = True

all_asset_names = [t for t, _ in st.session_state["downloaded_dfs"]] + [t for t, _ in st.session_state["uploaded_dfs"]]
for name in all_asset_names:
    with st.sidebar.expander(f"âš™ï¸ Ø¨ÛŒÙ…Ù‡ Ø¨Ø±Ø§ÛŒ {name}", expanded=False):
        st.markdown("<div dir='rtl'>Ø¨ÛŒÙ…Ù‡ Married Put ÛŒØ¹Ù†ÛŒ Ø§Ø®ØªÛŒØ§Ø± ÙØ±ÙˆØ´ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø±Ø§ÛŒÛŒ ÙØ¹Ø§Ù„ Ø§Ø³Øª ØªØ§ Ø±ÛŒØ²Ø´â€ŒÙ‡Ø§ÛŒ Ø´Ø¯ÛŒØ¯ Ø±Ø§ Ù¾ÙˆØ´Ø´ Ø¯Ù‡Ø¯.</div>", unsafe_allow_html=True)
        insured = st.checkbox(f"ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¨ÛŒÙ…Ù‡ Ø¨Ø±Ø§ÛŒ {name}", key=f"insured_{name}")
        if insured:
            loss_percent = st.number_input(f"ğŸ“‰ Ø¯Ø±ØµØ¯ Ø¶Ø±Ø± Ù…Ø¹Ø§Ù…Ù„Ù‡ Ù¾ÙˆØª Ø¨Ø±Ø§ÛŒ {name}", 0.0, 100.0, 30.0, step=0.01, key=f"loss_{name}")
            strike = st.number_input(f"ğŸ¯ Ù‚ÛŒÙ…Øª Ø§Ø¹Ù…Ø§Ù„ Ù¾ÙˆØª Ø¨Ø±Ø§ÛŒ {name}", 0.0, 1e6, 100.0, step=0.01, key=f"strike_{name}")
            premium = st.number_input(f"ğŸ’° Ù‚ÛŒÙ…Øª Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ù¾ÙˆØª Ø¨Ø±Ø§ÛŒ {name}", 0.0, 1e6, 5.0, step=0.01, key=f"premium_{name}")
            amount = st.number_input(f"ğŸ“¦ Ù…Ù‚Ø¯Ø§Ø± Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ø¨Ø±Ø§ÛŒ {name}", 0.0, 1e6, 1.0, step=0.01, key=f"amount_{name}")
            spot_price = st.number_input(f"ğŸ“Œ Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ Ø¯Ø§Ø±Ø§ÛŒÛŒ Ù¾Ø§ÛŒÙ‡ {name}", 0.0, 1e6, 100.0, step=0.01, key=f"spot_{name}")
            asset_amount = st.number_input(f"ğŸ“¦ Ù…Ù‚Ø¯Ø§Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ Ù¾Ø§ÛŒÙ‡ {name}", 0.0, 1e6, 1.0, step=0.01, key=f"base_{name}")
            st.session_state["insured_assets"][name] = {
                'loss_percent': loss_percent,
                'strike': strike,
                'premium': premium,
                'amount': amount,
                'spot': spot_price,
                'base': asset_amount
            }
        else:
            st.session_state["insured_assets"].pop(name, None)

st.sidebar.markdown("<hr/>", unsafe_allow_html=True)
st.sidebar.markdown("### Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ÙˆØ²Ù† Ù‡Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±ØªÙÙˆ")
min_weights = {}
max_weights = {}
for name in all_asset_names:
    min_weights[name] = st.sidebar.number_input(f"Ø­Ø¯Ø§Ù‚Ù„ ÙˆØ²Ù† {name} (%)", 0.0, 100.0, 0.0, 1.0) / 100
    max_weights[name] = st.sidebar.number_input(f"Ø­Ø¯Ø§Ú©Ø«Ø± ÙˆØ²Ù† {name} (%)", 0.0, 100.0, 100.0, 1.0) / 100

# ========== ØªØ­Ù„ÛŒÙ„ Ù¾Ø±ØªÙÙˆ ==========
if st.session_state["downloaded_dfs"] or st.session_state["uploaded_dfs"]:
    prices_df = pd.DataFrame()
    asset_names = []
    for t, df in st.session_state["downloaded_dfs"]:
        name = t
        if "Date" not in df.columns or "Price" not in df.columns:
            continue
        df = df.dropna(subset=['Date', 'Price'])
        df = df[['Date', 'Price']].set_index('Date')
        df.columns = [name]
        prices_df = df if prices_df.empty else prices_df.join(df, how='inner')
        asset_names.append(name)
    for t, df in st.session_state["uploaded_dfs"]:
        name = t
        if "Date" not in df.columns or "Price" not in df.columns:
            continue
        df = df.dropna(subset=['Date', 'Price'])
        df = df[['Date', 'Price']].set_index('Date')
        df.columns = [name]
        prices_df = df if prices_df.empty else prices_df.join(df, how='inner')
        asset_names.append(name)

    st.subheader("ğŸ“‰ Ø±ÙˆÙ†Ø¯ Ù‚ÛŒÙ…Øª Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§")
    st.line_chart(prices_df.resample(resample_rule).last().dropna())

    if prices_df.empty:
        st.error("âŒ Ø¯Ø§Ø¯Ù‡â€ŒÛŒ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        st.stop()

    try:
        resampled_prices = prices_df.resample(resample_rule).last().dropna()
        returns = resampled_prices.pct_change().dropna()
        mean_returns = returns.mean() * annual_factor
        cov_matrix = returns.cov() * annual_factor
        std_devs = np.sqrt(np.diag(cov_matrix))

        # ====== Ø§ÙØ²ÙˆØ¯Ù† Ø¯Ø§Ø±Ø§ÛŒÛŒ Ø¨Ø¯ÙˆÙ† Ø±ÛŒØ³Ú© ======
        asset_names_rf = asset_names + ["Ø¨Ø¯ÙˆÙ† Ø±ÛŒØ³Ú©"]
        mean_returns_rf = np.append(mean_returns.values, rf_rate)
        cov_matrix_rf = np.zeros((len(asset_names_rf), len(asset_names_rf)))
        cov_matrix_rf[:-1, :-1] = cov_matrix.values

        min_w = np.array([min_weights[n] for n in asset_names] + [0.0])
        max_w = np.array([max_weights[n] for n in asset_names] + [1.0])

        n_portfolios = 3000
        n_mc = 1000
        results = np.zeros((5 + len(asset_names_rf), n_portfolios))
        cvar_results = np.zeros((3 + len(asset_names_rf), n_portfolios))
        np.random.seed(42)
        for i in range(n_portfolios):
            while True:
                weights = np.random.random(len(asset_names_rf))
                weights = np.maximum(weights, min_w)
                weights = np.minimum(weights, max_w)
                weights /= np.sum(weights)
                if np.all(weights >= min_w) and np.all(weights <= max_w):
                    break
            sim_returns = np.random.multivariate_normal(mean_returns_rf, cov_matrix_rf, n_mc)
            for j, name in enumerate(asset_names):
                if name in st.session_state["insured_assets"]:
                    info = st.session_state["insured_assets"][name]
                    last_price = resampled_prices[name].iloc[-1]
                    final_prices = last_price * (1 + sim_returns[:, j])
                    put_pnl = np.maximum(info['strike'] - final_prices, 0) * info['amount'] - info['premium'] * info['amount']
                    asset_pnl = (final_prices - last_price) * info['base']
                    total_pnl = asset_pnl + put_pnl
                    sim_returns[:, j] = total_pnl / (last_price * max(info['base'], 1e-8))
            port_mc_returns = np.dot(sim_returns, weights)
            port_return = port_mc_returns.mean()
            port_std = port_mc_returns.std()
            sharpe_ratio = (port_return - rf_rate) / port_std if port_std > 0 else 0
            sortino_ratio = (port_return - rf_rate) / (port_mc_returns[port_mc_returns < 0].std() if np.any(port_mc_returns < 0) else 1)
            VaR = np.percentile(port_mc_returns, (1 - cvar_alpha) * 100)
            CVaR = port_mc_returns[port_mc_returns <= VaR].mean() if np.any(port_mc_returns <= VaR) else VaR
            results[0, i] = port_return
            results[1, i] = port_std
            results[2, i] = sharpe_ratio
            results[3, i] = sortino_ratio
            results[4, i] = -CVaR
            results[5:, i] = weights
            cvar_results[0, i] = port_std
            cvar_results[1, i] = port_return
            cvar_results[2, i] = -CVaR
            cvar_results[3:, i] = weights

        best_idx = np.argmin(np.abs(results[1] - user_risk))
        best_weights = results[5:, best_idx]
        best_cvar_idx = np.argmin(results[4])
        best_cvar_weights = results[5:, best_cvar_idx]

        st.subheader("ğŸ“Š Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø®Ù„Ø§ØµÙ‡ Ù¾Ø±ØªÙÙˆ")
        show_periodic_risk_return(resampled_prices, best_weights[:-1], "Ù¾Ø±ØªÙÙˆ Ø¨Ù‡ÛŒÙ†Ù‡ Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ")
        show_periodic_risk_return(resampled_prices, best_cvar_weights[:-1], f"Ù¾Ø±ØªÙÙˆ Ø¨Ù‡ÛŒÙ†Ù‡ CVaR ({int(cvar_alpha*100)}%)")

        # ====== Ù…Ø±Ø² Ú©Ø§Ø±Ø§ Ùˆ MPT ======
        ef_results, ef_weights = efficient_frontier(mean_returns, cov_matrix, annual_factor, points=200,
                                                    min_weights=np.array([min_weights[n] for n in asset_names]),
                                                    max_weights=np.array([max_weights[n] for n in asset_names]))
        max_sharpe_idx_ef = np.argmax(ef_results[2])
        mpt_weights = ef_weights[max_sharpe_idx_ef]

        # Ù†Ù…Ø§ÛŒØ´ Ù¾Ø±ØªÙÙˆ MPT
        st.subheader("ğŸ“Š Ù¾Ø±ØªÙÙˆ Ø¨Ù‡ÛŒÙ†Ù‡ Ø¨Ø± Ù…Ø¨Ù†Ø§ÛŒ Ù…Ø±Ø² Ú©Ø§Ø±Ø§ (MPT)")
        pf_prices_mpt = (resampled_prices * mpt_weights).sum(axis=1)
        pf_returns_mpt = pf_prices_mpt.pct_change().dropna()
        mean_ann_mpt = pf_returns_mpt.mean() * annual_factor
        risk_ann_mpt = pf_returns_mpt.std() * (annual_factor ** 0.5)
        st.markdown(
            f"""<div dir="rtl" style="text-align:right">
            <b>Ø³Ø§Ù„Ø§Ù†Ù‡:</b> Ø¨Ø§Ø²Ø¯Ù‡: {mean_ann_mpt:.2%} | Ø±ÛŒØ³Ú©: {risk_ann_mpt:.2%}<br>
            <b>ÙˆØ²Ù† Ù¾Ø±ØªÙÙˆ:</b> {' | '.join([f"{n}: {w:.2%}" for n, w in zip(asset_names, mpt_weights)])}
            </div>
            """, unsafe_allow_html=True)

        # Ù†Ù…ÙˆØ¯Ø§Ø± Ù…Ø±Ø² Ú©Ø§Ø±Ø§ (ØªØ±Ú©ÛŒØ¨ÛŒ)
        fig_all = go.Figure()
        # Ù…Ø±Ø² Ú©Ø§Ø±Ø§
        fig_all.add_trace(go.Scatter(
            x=ef_results[0]*100, y=ef_results[1]*100,
            mode='lines+markers', marker=dict(color='gray', size=5), name='Ù…Ø±Ø² Ú©Ø§Ø±Ø§ (MPT)'
        ))
        # Ù¾Ø±ØªÙÙˆ Ø¨Ù‡ÛŒÙ†Ù‡ MC
        fig_all.add_trace(go.Scatter(
            x=[results[1, best_idx]*100], y=[results[0, best_idx]*100],
            mode='markers+text', marker=dict(size=14, color='blue', symbol='diamond'),
            text=["MC"], textposition="top right", name='Ù¾Ø±ØªÙÙˆ Ø¨Ù‡ÛŒÙ†Ù‡ Monte Carlo'
        ))
        # Ù¾Ø±ØªÙÙˆ Ø¨Ù‡ÛŒÙ†Ù‡ CVaR
        fig_all.add_trace(go.Scatter(
            x=[cvar_results[0, best_cvar_idx]*100], y=[cvar_results[1, best_cvar_idx]*100],
            mode='markers+text', marker=dict(size=14, color='orange', symbol='triangle-up'),
            text=["CVaR"], textposition="top center", name='Ù¾Ø±ØªÙÙˆ Ø¨Ù‡ÛŒÙ†Ù‡ CVaR'
        ))
        # Ù¾Ø±ØªÙÙˆ Ø¨Ù‡ÛŒÙ†Ù‡ MPT
        fig_all.add_trace(go.Scatter(
            x=[ef_results[0, max_sharpe_idx_ef]*100], y=[ef_results[1, max_sharpe_idx_ef]*100],
            mode='markers+text', marker=dict(size=16, color='red', symbol='star'),
            text=["MPT"], textposition="bottom right", name='Ù¾Ø±ØªÙÙˆ Ø¨Ù‡ÛŒÙ†Ù‡ MPT'
        ))
        fig_all.update_layout(
            title="Ù…Ø±Ø² Ú©Ø§Ø±Ø§ Ø¨Ø§ Ù†Ù…Ø§ÛŒØ´ Ù¾Ø±ØªÙÙˆÙ‡Ø§ÛŒ Ù…Ù†ØªØ®Ø¨ (MC, CVaR, MPT)",
            xaxis_title="Ø±ÛŒØ³Ú© (%)",
            yaxis_title="Ø¨Ø§Ø²Ø¯Ù‡ (%)"
        )
        st.plotly_chart(fig_all, use_container_width=True)

        # ====== Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… Ø³ÙˆØ¯/Ø²ÛŒØ§Ù† Ù¾Ø±ØªÙÙˆ Ø¨Ø§ Ùˆ Ø¨Ø¯ÙˆÙ† Ø¨ÛŒÙ…Ù‡ ======
        st.subheader("ğŸ“‰ Ù…Ù‚Ø§ÛŒØ³Ù‡ ØªÙˆØ²ÛŒØ¹ Ø³ÙˆØ¯/Ø²ÛŒØ§Ù† Ù¾Ø±ØªÙÙˆ Ù‚Ø¨Ù„ Ùˆ Ø¨Ø¹Ø¯ Ø§Ø² Ø¨ÛŒÙ…Ù‡ (Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Û±Û°Ù¬Û°Û°Û° Ù…Ø±ØªØ¨Ù‡)")
        n_sim_hist = 10000
        sim_returns_noins = np.random.multivariate_normal(mean_returns_rf, cov_matrix_rf, n_sim_hist)
        port_mc_returns_noins = np.dot(sim_returns_noins, best_weights)
        VaR_noins = np.percentile(port_mc_returns_noins, (1-cvar_alpha)*100)
        cvar_noins = port_mc_returns_noins[port_mc_returns_noins <= VaR_noins].mean()
        loss_prob_noins = np.mean(port_mc_returns_noins < 0)

        sim_returns_ins = sim_returns_noins.copy()
        for j, name in enumerate(asset_names):
            if name in st.session_state["insured_assets"]:
                info = st.session_state["insured_assets"][name]
                last_price = resampled_prices[name].iloc[-1]
                final_prices = last_price * (1 + sim_returns_ins[:, j])
                put_pnl = np.maximum(info['strike'] - final_prices, 0) * info['amount'] - info['premium'] * info['amount']
                asset_pnl = (final_prices - last_price) * info['base']
                total_pnl = asset_pnl + put_pnl
                sim_returns_ins[:, j] = total_pnl / (last_price * max(info['base'], 1e-8))
        port_mc_returns_ins = np.dot(sim_returns_ins, best_weights)
        VaR_ins = np.percentile(port_mc_returns_ins, (1-cvar_alpha)*100)
        cvar_ins = port_mc_returns_ins[port_mc_returns_ins <= VaR_ins].mean()
        loss_prob_ins = np.mean(port_mc_returns_ins < 0)

        fig_hist = go.Figure()
        fig_hist.add_trace(go.Histogram(
            x=port_mc_returns_noins, nbinsx=50, opacity=0.5, name="Ø¨Ø¯ÙˆÙ† Ø¨ÛŒÙ…Ù‡", marker_color='red'
        ))
        fig_hist.add_trace(go.Histogram(
            x=port_mc_returns_ins, nbinsx=50, opacity=0.5, name="Ø¨Ø§ Ø¨ÛŒÙ…Ù‡", marker_color='green'
        ))
        fig_hist.add_vline(x=cvar_noins, line_dash="dashdot", line_color="red",
                           annotation_text=f"CVaR Ø¨Ø¯ÙˆÙ† Ø¨ÛŒÙ…Ù‡: {cvar_noins:.2%}", annotation_position="bottom left")
        fig_hist.add_vline(x=cvar_ins, line_dash="dashdot", line_color="green",
                           annotation_text=f"CVaR Ø¨Ø§ Ø¨ÛŒÙ…Ù‡: {cvar_ins:.2%}", annotation_position="bottom right")
        fig_hist.add_vline(x=VaR_noins, line_dash="dot", line_color="red", annotation_text="VaR Ø¨Ø¯ÙˆÙ† Ø¨ÛŒÙ…Ù‡", annotation_position="top left")
        fig_hist.add_vline(x=VaR_ins, line_dash="dot", line_color="green", annotation_text="VaR Ø¨Ø§ Ø¨ÛŒÙ…Ù‡", annotation_position="top right")
        fig_hist.update_layout(
            barmode='overlay',
            title="Ù…Ù‚Ø§ÛŒØ³Ù‡ ØªÙˆØ²ÛŒØ¹ Ø³ÙˆØ¯/Ø²ÛŒØ§Ù† Ù¾Ø±ØªÙÙˆ Ù‚Ø¨Ù„ Ùˆ Ø¨Ø¹Ø¯ Ø§Ø² Ø¨ÛŒÙ…Ù‡",
            xaxis_title="Ø¨Ø§Ø²Ø¯Ù‡ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒâ€ŒØ´Ø¯Ù‡ Ù¾Ø±ØªÙÙˆ",
            yaxis_title="ØªØ¹Ø¯Ø§Ø¯",
            legend=dict(x=0.7, y=0.95)
        )
        st.plotly_chart(fig_hist, use_container_width=True)
        st.markdown(f"""
        <div dir="rtl" style="text-align:right; font-size:16px">
        <b>CVaR Ø¨Ø¯ÙˆÙ† Ø¨ÛŒÙ…Ù‡:</b> <span style="color:red">{cvar_noins:.2%}</span><br>
        <b>CVaR Ø¨Ø§ Ø¨ÛŒÙ…Ù‡:</b> <span style="color:green">{cvar_ins:.2%}</span><br>
        <b>Ø§Ø­ØªÙ…Ø§Ù„ Ø²ÛŒØ§Ù† (Ø¨Ø¯ÙˆÙ† Ø¨ÛŒÙ…Ù‡):</b> <span style="color:red">{loss_prob_noins:.2%}</span><br>
        <b>Ø§Ø­ØªÙ…Ø§Ù„ Ø²ÛŒØ§Ù† (Ø¨Ø§ Ø¨ÛŒÙ…Ù‡):</b> <span style="color:green">{loss_prob_ins:.2%}</span>
        </div>
        """, unsafe_allow_html=True)
        st.info("Ù‡Ù…Ø§Ù†Ø·ÙˆØ± Ú©Ù‡ Ø¯Ø± Ù†Ù…ÙˆØ¯Ø§Ø± Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯ØŒ **Ø¨Ø§ ÙØ¹Ø§Ù„ Ø´Ø¯Ù† Ø¨ÛŒÙ…Ù‡ØŒ Ø§Ù†ØªÙ‡Ø§ÛŒ Ø³Ù…Øª Ú†Ù¾ (Ø¯Ù… Ù…Ù†ÙÛŒ) ØªÙˆØ²ÛŒØ¹ Ø³ÙˆØ¯/Ø²ÛŒØ§Ù† Ú©ÙˆØªØ§Ù‡â€ŒØªØ± Ø´Ø¯Ù‡ Ùˆ Ø§Ø­ØªÙ…Ø§Ù„ Ø²ÛŒØ§Ù†â€ŒÙ‡Ø§ÛŒ Ø´Ø¯ÛŒØ¯ Ùˆ Ù…Ù‚Ø¯Ø§Ø± CVaR Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØªÙ‡ Ø§Ø³Øª. Ø§ÛŒÙ† ÛŒØ¹Ù†ÛŒ Ø¨ÛŒÙ…Ù‡ Ù¾ÙˆØ±ØªÙÙˆ Ø±ÛŒØ³Ú© Ø²ÛŒØ§Ù†â€ŒÙ‡Ø§ÛŒ Ø³Ù†Ú¯ÛŒÙ† Ø±Ø§ Ú©Ø§Ù‡Ø´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ØŒ Ø­ØªÛŒ Ø§Ú¯Ø± Ù…Ù‚Ø¯Ø§Ø± Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÛŒØ§Ø± (Ø±ÛŒØ³Ú© Ú©Ù„ÛŒ) Ø®ÛŒÙ„ÛŒ ØªØºÛŒÛŒØ± Ù†Ú©Ù†Ø¯.")

    except Exception as e:
        st.error(f"Ø®Ø·Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù¾Ø±ØªÙÙˆ: {e}")

else:
    st.warning("âš ï¸ Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSV Ø´Ø§Ù…Ù„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Date Ùˆ Price ÛŒØ§ Close ÛŒØ§ Open Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ø§Ø² Ø¨Ø®Ø´ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø¯Ø§Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.")
