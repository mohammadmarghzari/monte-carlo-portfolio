import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import yfinance as yf
import io
import re

st.set_page_config(page_title="ØªØ­Ù„ÛŒÙ„ Ù¾Ø±ØªÙÙˆ Ø¨Ø§ Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„ÙˆØŒ CVaR Ùˆ Married Put", layout="wide")
st.title("ğŸ“Š Ø§Ø¨Ø²Ø§Ø± ØªØ­Ù„ÛŒÙ„ Ù¾Ø±ØªÙÙˆ Ø¨Ø§ Ø±ÙˆØ´ Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„ÙˆØŒ CVaR Ùˆ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Married Put")

with st.expander("ğŸ“„ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ ÙØ§ÛŒÙ„ ÙˆØ±ÙˆØ¯ÛŒ (csv ÛŒØ§ txt)"):
    st.markdown("""
    <div dir="rtl" style="text-align: right;">
    <b>Ø¨Ø±Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ ØµØ­ÛŒØ­ Ø§Ø¨Ø²Ø§Ø±:</b> ÙÙ‚Ø· Ø¯Ùˆ Ø³ØªÙˆÙ† <b>Date</b> Ùˆ <b>Price</b> Ú©Ø§ÙÛŒ Ø§Ø³Øª.<br>
    Ø³Ø§ÛŒØ± Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ (Open, High, Low, Volume, ...) Ø­Ø°Ù Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.<br>
    Ø§Ø¨Ø²Ø§Ø± Ø¨Ù‡ Ø·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± ÙØ§ÛŒÙ„ Ø±Ø§ ØªÙ…ÛŒØ² Ù…ÛŒâ€ŒÚ©Ù†Ø¯Ø› Ø§Ù…Ø§ Ø§Ú¯Ø± Ø¨Ù‡ Ø®Ø·Ø§ Ø®ÙˆØ±Ø¯ÛŒØ¯ØŒ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ ÙØ§ÛŒÙ„ Ø´Ù…Ø§ Ù…Ø§Ù†Ù†Ø¯ Ù†Ù…ÙˆÙ†Ù‡ Ø²ÛŒØ± Ø¨Ø§Ø´Ø¯:
    </div>
    """, unsafe_allow_html=True)
    st.code(
"""Date,Price
2025-06-02,13.86
2025-06-01,14.06
""", language="text")
    st.info("Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ø´Ù…Ø§ Ø³ØªÙˆÙ† Ø§Ø¶Ø§ÙÛŒ Ø¯Ø§Ø´Øª ÛŒØ§ Ø¹Ø¯Ø¯Ù‡Ø§ Ø¯Ø± Ú©ÙˆØªÛŒØ´Ù† Ø¨ÙˆØ¯Ù†Ø¯ØŒ Ù†Ú¯Ø±Ø§Ù† Ù†Ø¨Ø§Ø´ÛŒØ¯! Ø§Ø¨Ø²Ø§Ø± Ø¨Ù‡â€ŒØ·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± ØªÙ…ÛŒØ² Ù…ÛŒâ€ŒÚ©Ù†Ø¯.")

sample_txt = """# Ù†Ù…ÙˆÙ†Ù‡ ÙØ§ÛŒÙ„ txt Ø¨Ø±Ø§ÛŒ Ø§Ø¨Ø²Ø§Ø± ØªØ­Ù„ÛŒÙ„ Ù¾Ø±ØªÙÙˆ
Date,Price
2025-06-02,13.86
2025-06-01,14.06
"""
st.download_button("Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ù…ÙˆÙ†Ù‡ ÙØ§ÛŒÙ„ txt", sample_txt, file_name="sample.txt", mime="text/plain")

def smart_read_file(file):
    try:
        content = file.read()
        try:
            content = content.decode("utf-8")
        except Exception:
            content = content.decode("latin1")
        seps = [',',';','|','\t']
        sep_counts = [(s, content.count(s)) for s in seps]
        sep = max(sep_counts, key=lambda x:x[1])[0] if max(sep_counts, key=lambda x:x[1])[1] > 0 else ','
        lines = [l.strip() for l in content.splitlines() if l.strip() and not l.strip().startswith('#')]
        if not lines:
            return None
        header = [x.strip().replace('"','').replace("'",'') for x in re.split(sep, lines[0])]
        def find_col(colnames, candidates):
            for c in candidates:
                for i, h in enumerate(colnames):
                    if c.lower() in h.lower():
                        return i
            return None
        date_idx = find_col(header, ['date', 'ØªØ§Ø±ÛŒØ®'])
        price_idx = find_col(header, ['price', 'Ù‚ÛŒÙ…Øª'])
        if date_idx is None or price_idx is None:
            return None
        data_rows = []
        for row in lines[1:]:
            parts = [x.strip().replace('"','').replace("'",'') for x in re.split(sep, row)]
            if len(parts) <= max(date_idx, price_idx): continue
            date_val = parts[date_idx]
            price_val = parts[price_idx]
            price_val = price_val.replace(' ', '').replace(',', '.')
            price_val = re.sub(r'[^\d\.\-]', '', price_val)
            try:
                price_float = float(price_val)
            except:
                continue
            data_rows.append([date_val, price_float])
        if not data_rows:
            return None
        df = pd.DataFrame(data_rows, columns=['Date', 'Price'])
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
        df = df.dropna(subset=['Date', 'Price'])
        df = df.sort_values('Date')
        if len(df) < 3:
            return None
        return df
    except Exception as e:
        return None

st.sidebar.header("ğŸ“‚ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ (CSV ÛŒØ§ TXT)")
uploaded_files = st.sidebar.file_uploader(
    "Ú†Ù†Ø¯ ÙØ§ÛŒÙ„ CSV ÛŒØ§ TXT Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ (Ù‡Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ ÛŒÚ© ÙØ§ÛŒÙ„)",
    type=['csv', 'txt'],
    accept_multiple_files=True,
    key="uploader"
)

period = st.sidebar.selectbox("Ø¨Ø§Ø²Ù‡ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø¯Ù‡", ['Ù…Ø§Ù‡Ø§Ù†Ù‡', 'Ø³Ù‡â€ŒÙ…Ø§Ù‡Ù‡', 'Ø´Ø´â€ŒÙ…Ø§Ù‡Ù‡'])
resample_rule = {'Ù…Ø§Ù‡Ø§Ù†Ù‡': 'M', 'Ø³Ù‡â€ŒÙ…Ø§Ù‡Ù‡': 'Q', 'Ø´Ø´â€ŒÙ…Ø§Ù‡Ù‡': '2Q'}[period]
annual_factor = {'Ù…Ø§Ù‡Ø§Ù†Ù‡': 12, 'Ø³Ù‡â€ŒÙ…Ø§Ù‡Ù‡': 4, 'Ø´Ø´â€ŒÙ…Ø§Ù‡Ù‡': 2}[period]
user_risk = st.sidebar.slider("Ø±ÛŒØ³Ú© Ù‡Ø¯Ù Ù¾Ø±ØªÙÙˆ (Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÛŒØ§Ø± Ø³Ø§Ù„Ø§Ù†Ù‡)", 0.01, 1.0, 0.25, 0.01)
cvar_alpha = st.sidebar.slider("Ø³Ø·Ø­ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† CVaR", 0.80, 0.99, 0.95, 0.01)

with st.sidebar.expander("ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø§Ø² ÛŒØ§Ù‡Ùˆ ÙØ§ÛŒÙ†Ø§Ù†Ø³"):
    st.markdown("""
    <div dir="rtl" style="text-align: right; font-size: 14px">
    <b>Ø±Ø§Ù‡Ù†Ù…Ø§:</b><br>
    - Ù†Ù…Ø§Ø¯ Ù‡Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ Ø±Ø§ Ù…Ø·Ø§Ø¨Ù‚ Ø³Ø§ÛŒØª ÛŒØ§Ù‡Ùˆ ÙØ§ÛŒÙ†Ø§Ù†Ø³ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.<br>
    - Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø±Ø§ Ø¨Ø§ Ú©Ø§Ù…Ø§ Ùˆ Ø¨Ø¯ÙˆÙ† ÙØ§ØµÙ„Ù‡ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.<br>
    - Ù…Ø«Ø§Ù„: <b>BTC-USD,AAPL,GOOGL,ETH-USD</b>
    </div>
    """, unsafe_allow_html=True)
    tickers_input = st.text_input("Ù†Ù…Ø§Ø¯ Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ (Ø¨Ø§ Ú©Ø§Ù…Ø§ Ùˆ Ø¨Ø¯ÙˆÙ† ÙØ§ØµÙ„Ù‡)")
    start = st.date_input("ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹", value=pd.to_datetime("2023-01-01"))
    end = st.date_input("ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†", value=pd.to_datetime("today"))
    download_btn = st.button("Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø¢Ù†Ù„Ø§ÛŒÙ†")

downloaded_dfs = []
if download_btn and tickers_input.strip():
    tickers = [t.strip() for t in tickers_input.strip().split(",") if t.strip()]
    try:
        data = yf.download(tickers, start=start, end=end, progress=False, group_by='ticker', auto_adjust=True)
        if not data.empty:
            for t in tickers:
                if len(tickers) == 1:
                    df = data.reset_index()[['Date', 'Close']].rename(columns={'Close': 'Price'})
                else:
                    if t in data.columns.levels[0]:
                        df_t = data[t].reset_index()[['Date', 'Close']].rename(columns={'Close': 'Price'})
                        df = df_t
                    else:
                        st.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯ {t} Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                        continue
                df['Date'] = pd.to_datetime(df['Date'])
                downloaded_dfs.append((t, df))
                st.success(f"Ø¯Ø§Ø¯Ù‡ {t} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯.")
        else:
            st.error("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯!")
    except Exception as ex:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡: {ex}")

if downloaded_dfs:
    st.markdown('<div dir="rtl" style="text-align: right;"><b>Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯Ø´Ø¯Ù‡ Ø§Ø² ÛŒØ§Ù‡Ùˆ ÙØ§ÛŒÙ†Ø§Ù†Ø³:</b></div>', unsafe_allow_html=True)
    for t, df in downloaded_dfs:
        st.markdown(f"<div dir='rtl' style='text-align: right;'><b>{t}</b></div>", unsafe_allow_html=True)
        st.dataframe(df.head())

def get_unique_name(existing_names, base_name):
    if base_name not in existing_names:
        return base_name
    i = 2
    while f"{base_name}_{i}" in existing_names:
        i += 1
    return f"{base_name}_{i}"

if uploaded_files or downloaded_dfs:
    prices_df = pd.DataFrame()
    asset_names = []
    existing_names = set()

    # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯Ø´Ø¯Ù‡
    for t, df in downloaded_dfs:
        name = get_unique_name(existing_names, t)
        existing_names.add(name)
        if 'Date' not in df.columns or 'Price' not in df.columns:
            st.warning(f"Ø¯Ø§Ø¯Ù‡ Ø¢Ù†Ù„Ø§ÛŒÙ† {name} Ø¨Ø§ÛŒØ¯ Ø¯Ø§Ø±Ø§ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ 'Date' Ùˆ 'Price' Ø¨Ø§Ø´Ø¯.")
            continue
        df = df.dropna(subset=['Date', 'Price'])
        df = df[['Date', 'Price']].set_index('Date')
        df.columns = [name]
        prices_df = df if prices_df.empty else prices_df.join(df, how='inner')
        asset_names.append(name)

    # ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ÛŒ Ú©Ø§Ø±Ø¨Ø±
    for file in uploaded_files:
        base_name = file.name.split('.')[0]
        name = get_unique_name(existing_names, base_name)
        existing_names.add(name)
        df = smart_read_file(file)
        if df is None or 'Date' not in df.columns or 'Price' not in df.columns or len(df) < 3:
            st.warning(f"ÙØ§ÛŒÙ„ {name} Ø¨Ø§ÛŒØ¯ Ø¯Ø§Ø±Ø§ÛŒ Ø­Ø¯Ø§Ù‚Ù„ Ø³Ù‡ Ø³Ø·Ø± Ø¯Ø§Ø¯Ù‡ Ùˆ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ 'Date' Ùˆ 'Price' Ø¨Ø§Ø´Ø¯.")
            continue
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
        df['Price'] = pd.to_numeric(df['Price'], errors='coerce')
        df = df.dropna(subset=['Date', 'Price'])
        df = df[['Date', 'Price']].set_index('Date')
        df.columns = [name]
        prices_df = df if prices_df.empty else prices_df.join(df, how='inner')
        asset_names.append(name)

    if prices_df.empty or prices_df.shape[1] < 2:
        st.error("âŒ Ø¯Ø§Ø¯Ù‡â€ŒÛŒ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ø­Ø¯Ø§Ù‚Ù„ Ø¯Ùˆ Ø¯Ø§Ø±Ø§ÛŒÛŒ Ù…Ø¹ØªØ¨Ø± Ù†Ø¯Ø§Ø±ÛŒØ¯.")
        st.stop()

    st.subheader("ğŸ§ª Ù¾ÛŒØ´â€ŒÙ†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§")
    st.dataframe(prices_df.tail())
    prices_df = prices_df.dropna(axis=1, how='any')
    if prices_df.shape[1] < 2:
        st.error("Ø­Ø¯Ø§Ù‚Ù„ Ø¯Ùˆ Ø¯Ø§Ø±Ø§ÛŒÛŒ Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ§Ø² Ø§Ø³Øª (Ù‡Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ Ø³ØªÙˆÙ† Ø¬Ø¯Ø§).")
        st.stop()

    resampled_prices = prices_df.resample(resample_rule).last().dropna()
    returns = resampled_prices.pct_change().dropna()
    mean_returns = returns.mean() * annual_factor
    cov_matrix = returns.cov() * annual_factor
    std_devs = np.sqrt(np.diag(cov_matrix))

    # Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù„Ø§Ù…Øª Ú©ÙˆÙˆØ§Ø±ÛŒØ§Ù†Ø³
    if np.any(np.isnan(cov_matrix)) or np.any(np.isinf(cov_matrix)):
        st.error("Ù…Ø§ØªØ±ÛŒØ³ Ú©ÙˆÙˆØ§Ø±ÛŒØ§Ù†Ø³ Ù†Ø§Ø³Ø§Ù„Ù… Ø§Ø³Øª (Ø´Ø§Ù…Ù„ NaN ÛŒØ§ Inf). Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯ (Ù…Ø«Ù„Ø§Ù‹ Ø¯Ø§Ø¯Ù‡ Ú©Ù… ÛŒØ§ ÙØ§ÛŒÙ„ Ø®Ø±Ø§Ø¨).")
        st.stop()
    if not np.allclose(cov_matrix, cov_matrix.T):
        st.error("Ù…Ø§ØªØ±ÛŒØ³ Ú©ÙˆÙˆØ§Ø±ÛŒØ§Ù†Ø³ Ù…ØªÙ‚Ø§Ø±Ù† Ù†ÛŒØ³Øª.")
        st.stop()
    eigvals = np.linalg.eigvals(cov_matrix)
    if np.any(eigvals <= 0):
        st.error("Ù…Ø§ØªØ±ÛŒØ³ Ú©ÙˆÙˆØ§Ø±ÛŒØ§Ù†Ø³ Ù…Ø«Ø¨Øª Ù…Ø¹ÛŒÙ† Ù†ÛŒØ³Øª ÛŒØ§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª ÛŒØ§ Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ø¯Ø§Ø±ÛŒØ¯.")
        st.stop()

    n_portfolios = 8000
    n_mc = 1000
    results = np.zeros((5 + len(asset_names), n_portfolios))
    np.random.seed(42)
    rf = 0

    downside = returns.copy()
    downside[downside > 0] = 0

    for i in range(n_portfolios):
        weights = np.random.random(len(asset_names))
        weights /= np.sum(weights)
        port_return = np.dot(weights, mean_returns)
        port_std = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
        downside_risk = np.sqrt(np.dot(weights.T, np.dot(downside.cov() * annual_factor, weights)))
        sharpe_ratio = (port_return - rf) / port_std
        sortino_ratio = (port_return - rf) / downside_risk if downside_risk > 0 else np.nan

        mc_sims = np.random.multivariate_normal(mean_returns/annual_factor, cov_matrix/annual_factor, n_mc)
        port_mc_returns = np.dot(mc_sims, weights)
        VaR = np.percentile(port_mc_returns, (1 - cvar_alpha) * 100)
        CVaR = port_mc_returns[port_mc_returns <= VaR].mean() if np.any(port_mc_returns <= VaR) else VaR

        results[0, i] = port_return
        results[1, i] = port_std
        results[2, i] = sharpe_ratio
        results[3, i] = sortino_ratio
        results[4, i] = -CVaR
        results[5:, i] = weights

    results_df = pd.DataFrame(results.T, columns=['Return', 'Risk', 'Sharpe', 'Sortino', 'CVaR'] + asset_names)
    max_sharpe = results_df.iloc[results_df['Sharpe'].idxmax()]
    min_risk = results_df.iloc[results_df['Risk'].idxmin()]
    min_cvar = results_df.iloc[results_df['CVaR'].idxmin()]

    st.markdown("### âš¡ Ø¨Ù‡ØªØ±ÛŒÙ† Ù¾Ø±ØªÙÙˆ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø´Ø§Ø±Ù¾:")
    st.table(pd.DataFrame({
        'ÙˆØ²Ù†': max_sharpe[asset_names].round(4),
        'Ù†Ø§Ù… Ø¯Ø§Ø±Ø§ÛŒÛŒ': asset_names
    }).set_index('Ù†Ø§Ù… Ø¯Ø§Ø±Ø§ÛŒÛŒ').T)
    st.info(f"Ø¨Ø§Ø²Ø¯Ù‡ Ø³Ø§Ù„Ø§Ù†Ù‡: {max_sharpe['Return']:.2%}   |   Ø±ÛŒØ³Ú© (Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÛŒØ§Ø±): {max_sharpe['Risk']:.2%}   |   Ø´Ø§Ø±Ù¾: {max_sharpe['Sharpe']:.2f}")

    st.markdown("### âš¡ Ø§Ù…Ù†â€ŒØªØ±ÛŒÙ† Ù¾Ø±ØªÙÙˆ (Ú©Ù…ØªØ±ÛŒÙ† Ø±ÛŒØ³Ú©):")
    st.table(pd.DataFrame({
        'ÙˆØ²Ù†': min_risk[asset_names].round(4),
        'Ù†Ø§Ù… Ø¯Ø§Ø±Ø§ÛŒÛŒ': asset_names
    }).set_index('Ù†Ø§Ù… Ø¯Ø§Ø±Ø§ÛŒÛŒ').T)
    st.info(f"Ø¨Ø§Ø²Ø¯Ù‡ Ø³Ø§Ù„Ø§Ù†Ù‡: {min_risk['Return']:.2%}   |   Ø±ÛŒØ³Ú© (Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÛŒØ§Ø±): {min_risk['Risk']:.2%}")

    st.markdown("### âš¡ Ù¾Ø±ØªÙÙˆ Ø¨Ø§ Ú©Ù…ØªØ±ÛŒÙ† CVaR:")
    st.table(pd.DataFrame({
        'ÙˆØ²Ù†': min_cvar[asset_names].round(4),
        'Ù†Ø§Ù… Ø¯Ø§Ø±Ø§ÛŒÛŒ': asset_names
    }).set_index('Ù†Ø§Ù… Ø¯Ø§Ø±Ø§ÛŒÛŒ').T)
    st.info(f"Ø¨Ø§Ø²Ø¯Ù‡ Ø³Ø§Ù„Ø§Ù†Ù‡: {min_cvar['Return']:.2%}   |   CVaR: {min_cvar['CVaR']:.2%}")

    st.markdown("### ğŸ“ˆ Ù†Ù…ÙˆØ¯Ø§Ø± Ø±ÛŒØ³Ú©/Ø¨Ø§Ø²Ø¯Ù‡ Ù¾Ø±ØªÙÙˆÙ‡Ø§ Ùˆ Ù†Ù‚Ø§Ø· Ø¨Ù‡ÛŒÙ†Ù‡")
    fig = px.scatter(results_df, x='Risk', y='Return', color='Sharpe', hover_data=asset_names,
                     title='Ù¾Ø±ØªÙÙˆÙ‡Ø§ÛŒ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒâ€ŒØ´Ø¯Ù‡ (Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ)')
    fig.add_scatter(x=[max_sharpe['Risk']], y=[max_sharpe['Return']],
                    mode='markers', marker=dict(color='red', size=15, symbol='star'),
                    name="Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø´Ø§Ø±Ù¾")
    fig.add_scatter(x=[min_risk['Risk']], y=[min_risk['Return']],
                    mode='markers', marker=dict(color='blue', size=12, symbol='circle'),
                    name="Ú©Ù…ØªØ±ÛŒÙ† Ø±ÛŒØ³Ú©")
    fig.add_scatter(x=[min_cvar['Risk']], y=[min_cvar['Return']],
                    mode='markers', marker=dict(color='orange', size=12, symbol='diamond'),
                    name="Ú©Ù…ØªØ±ÛŒÙ† CVaR")
    fig.update_layout(xaxis_title='Ø±ÛŒØ³Ú© (Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÛŒØ§Ø± Ø³Ø§Ù„Ø§Ù†Ù‡)', yaxis_title='Ø¨Ø§Ø²Ø¯Ù‡ Ø³Ø§Ù„Ø§Ù†Ù‡')
    st.plotly_chart(fig, use_container_width=True)

    st.markdown("### ğŸ—‚ Ø¬Ø¯ÙˆÙ„ Ú©Ø§Ù…Ù„ Ù¾Ø±ØªÙÙˆÙ‡Ø§ÛŒ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒâ€ŒØ´Ø¯Ù‡")
    st.dataframe(results_df.round(4))

    st.markdown("### ğŸ“Š Ù†Ù…ÙˆØ¯Ø§Ø± ÙˆØ²Ù†ÛŒ Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ø±ØªÙÙˆ Ø¨Ù‡ÛŒÙ†Ù‡ (Ø´Ø§Ø±Ù¾)")
    st.plotly_chart(px.pie(names=asset_names, values=max_sharpe[asset_names], title="ÙˆØ²Ù† Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ Ø¯Ø± Ù¾Ø±ØªÙÙˆ Ø¨Ø§ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø´Ø§Ø±Ù¾"), use_container_width=True)

else:
    st.warning("âš ï¸ Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSV ÛŒØ§ TXT Ù…Ø¹ØªØ¨Ø± Ø´Ø§Ù…Ù„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Date Ùˆ Price Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ø§Ø² Ø¨Ø®Ø´ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø¯Ø§Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.")
