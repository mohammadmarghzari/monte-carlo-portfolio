import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import yfinance as yf
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from io import BytesIO

st.set_page_config(page_title="ØªØ­Ù„ÛŒÙ„ Ù¾Ø±ØªÙÙˆ Ø¨Ø§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡", layout="wide")
st.title("ğŸ“Š Ø§Ø¨Ø²Ø§Ø± ØªØ­Ù„ÛŒÙ„ Ù¾Ø±ØªÙÙˆ: Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„ÙˆØŒ CVaRØŒ Married Put Ùˆ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡")

# --- Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ ---
with st.expander("ğŸ“˜ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø§Ø² ÛŒØ§Ù‡Ùˆ ÙØ§ÛŒÙ†Ø§Ù†Ø³"):
    st.markdown("""
    - Ù†Ù…Ø§Ø¯ Ø³Ù‡Ø§Ù… Ø±Ø§ Ø¨Ù‡ ÙØ±Ù…Øª ÛŒØ§Ù‡Ùˆ ÙØ§ÛŒÙ†Ø§Ù†Ø³ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ (Ù…Ø«Ø§Ù„: AAPL Ø¨Ø±Ø§ÛŒ Ø§Ù¾Ù„ØŒ MSFT Ø¨Ø±Ø§ÛŒ Ù…Ø§ÛŒÚ©Ø±ÙˆØ³Ø§ÙØª).
    - Ø¨Ø±Ø§ÛŒ Ø¨ÙˆØ±Ø³ ØªÙ‡Ø±Ø§Ù† Ù†Ù…Ø§Ø¯ Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª `Ù†Ù…Ø§Ø¯.IR` ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ (Ù…Ø«Ø§Ù„: ÙÙˆÙ„Ø§Ø¯.IR).
    - ÙˆØ²Ù† Ù¾Ø±ØªÙÙˆ Ø¨Ø§ÛŒØ¯ Ø¨ÛŒÙ† Û° Ùˆ Û± Ø¨Ø§Ø´Ø¯ Ùˆ Ù…Ø¬Ù…ÙˆØ¹ Ø¢Ù†â€ŒÙ‡Ø§ Û± Ø´ÙˆØ¯.
    - ØªØ¹Ø¯Ø§Ø¯ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÛŒØ§Ø² ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯.
    """)

with st.expander("ğŸ“— Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ù¾Ø±ØªÙÙˆ"):
    st.markdown("""
    **Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ Ø§Ù†ØªØ®Ø§Ø¨:**
    - **Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ:** Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ ØªØµØ§Ø¯ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ø±Ø²Ø´ Ø¢ÛŒÙ†Ø¯Ù‡ Ù¾Ø±ØªÙÙˆ.
    - **CVaR/VaR:** Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø±ÛŒØ³Ú© Ù¾Ø±ØªÙÙˆ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø²ÛŒØ§Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø­ØªÙ…Ù„ Ø¯Ø± Ø³Ø·ÙˆØ­ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ù…Ø®ØªÙ„Ù.
    - **Married Put:** Ù¾ÙˆØ´Ø´ Ø±ÛŒØ³Ú© Ø¨Ø§ Ø®Ø±ÛŒØ¯ Ø§Ø®ØªÛŒØ§Ø± ÙØ±ÙˆØ´ Ø¨Ø±Ø§ÛŒ Ù¾Ø±ØªÙÙˆ.
    - **Black-Litterman:** ØªØ±Ú©ÛŒØ¨ Ø¯ÛŒØ¯Ú¯Ø§Ù‡ Ø´Ø®ØµÛŒ Ø¨Ø§ Ù…Ø¯Ù„ Ù…Ø§Ø±Ú©ÙˆÛŒØªØ² Ø¨Ø±Ø§ÛŒ ØªØ®Ù…ÛŒÙ† Ø¨Ø§Ø²Ø¯Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡ Ù¾Ø±ØªÙÙˆ.
    - **Risk Parity:** ØªØ®ØµÛŒØµ Ø³Ø±Ù…Ø§ÛŒÙ‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ù‡Ù… Ù…Ø³Ø§ÙˆÛŒ Ù‡Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ Ø¯Ø± Ø±ÛŒØ³Ú© Ú©Ù„ Ù¾Ø±ØªÙÙˆ.
    - **ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† (Random Forest):** Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø§Ø²Ø¯Ù‡ Ù¾Ø±ØªÙÙˆ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ Ø¨Ø§ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø¬Ù†Ú¯Ù„ ØªØµØ§Ø¯ÙÛŒ.
    - **ØªØ­Ù„ÛŒÙ„ Ø³Ù†Ø§Ø±ÛŒÙˆ/Ø§Ø³ØªØ±Ø³ ØªØ³Øª:** Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ§Ú©Ù†Ø´ Ù¾Ø±ØªÙÙˆ Ø¨Ù‡ Ø´ÙˆÚ©â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø± Ùˆ Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ø¨Ø­Ø±Ø§Ù†ÛŒ.
    """)

# --- ÙˆØ±ÙˆØ¯ÛŒ Ú©Ø§Ø±Ø¨Ø± Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ùˆ ÙˆØ²Ù†â€ŒÙ‡Ø§ ---
st.sidebar.header("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾Ø±ØªÙÙˆ")
tickers = st.sidebar.text_area("Ù†Ù…Ø§Ø¯Ù‡Ø§ (Ø¨Ø§ ÙˆÛŒØ±Ú¯ÙˆÙ„ Ø¬Ø¯Ø§ Ú©Ù†ÛŒØ¯)", value="AAPL,MSFT,GOOGL")
weights_input = st.sidebar.text_area("ÙˆØ²Ù† Ù¾Ø±ØªÙÙˆ (Ø¨Ø§ ÙˆÛŒØ±Ú¯ÙˆÙ„ Ø¬Ø¯Ø§ Ú©Ù†ÛŒØ¯ØŒ Ù…Ø¬Ù…ÙˆØ¹=1)", value="0.4,0.3,0.3")
try:
    tickers = [t.strip() for t in tickers.split(",") if t.strip()]
    weights = [float(w.strip()) for w in weights_input.split(",") if w.strip()]
    assert len(tickers) == len(weights), "ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ùˆ ÙˆØ²Ù†â€ŒÙ‡Ø§ Ø¨Ø±Ø§Ø¨Ø± Ù†ÛŒØ³Øª."
    assert np.isclose(sum(weights), 1.0), "Ù…Ø¬Ù…ÙˆØ¹ ÙˆØ²Ù†â€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Û± Ø¨Ø§Ø´Ø¯."
except Exception as e:
    st.error(f"Ø®Ø·Ø§ Ø¯Ø± ÙˆØ±ÙˆØ¯ÛŒ: {e}")
    st.stop()

start_date = st.sidebar.date_input("ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹", pd.to_datetime("2020-01-01"))
end_date = st.sidebar.date_input("ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†", pd.to_datetime("today"))
n_sim = st.sidebar.number_input("ØªØ¹Ø¯Ø§Ø¯ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ", 100, 5000, 1000)
n_days = st.sidebar.number_input("ØªØ¹Ø¯Ø§Ø¯ Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ", 30, 365, 180)
confidence_level = st.sidebar.slider("Ø³Ø·Ø­ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† VaR/CVaR", 90, 99, 95)
initial_investment = st.sidebar.number_input("Ø³Ø±Ù…Ø§ÛŒÙ‡ Ø§ÙˆÙ„ÛŒÙ‡ (Ø¯Ù„Ø§Ø±)", 1000, 1000000, 10000)
put_strike_pct = st.sidebar.slider("Ø¯Ø±ØµØ¯ Ù‚ÛŒÙ…Øª Ø§Ø¹Ù…Ø§Ù„ Ø§Ø®ØªÛŒØ§Ø± ÙØ±ÙˆØ´ (Married Put)", 70, 100, 90)

# --- Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ ---
model_options = [
    "Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ",
    "CVaR/VaR",
    "Married Put",
    "Black-Litterman",
    "Risk Parity",
    "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† (Random Forest)",
    "ØªØ­Ù„ÛŒÙ„ Ø³Ù†Ø§Ø±ÛŒÙˆ/Ø§Ø³ØªØ±Ø³ ØªØ³Øª"
]
selected_models = st.sidebar.multiselect("Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡", model_options, default=model_options[:3])

# --- Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ---
@st.cache_data
def get_data(tickers, start, end):
    data = yf.download(tickers, start=start, end=end)["Adj Close"]
    if isinstance(data, pd.Series):
        data = data.to_frame()
    return data.dropna()

data = get_data(tickers, start_date, end_date)
st.subheader("Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®ÛŒ Ù¾Ø±ØªÙÙˆ")
st.dataframe(data.tail())

# --- Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø§Ø²Ø¯Ù‡ Ùˆ Ú©ÙˆÙˆØ§Ø±ÛŒØ§Ù†Ø³ ---
returns = data.pct_change().dropna()
mean_returns = returns.mean()
cov_matrix = returns.cov()

# --- Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆØ¯Ø§Ø± Ù‚ÛŒÙ…Øª ---
st.subheader("Ù†Ù…ÙˆØ¯Ø§Ø± Ù‚ÛŒÙ…Øª Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§")
fig = go.Figure()
for t in tickers:
    fig.add_trace(go.Scatter(x=data.index, y=data[t], name=t))
st.plotly_chart(fig, use_container_width=True)

# --- Ù…Ø¯Ù„ Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ ---
if "Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ" in selected_models:
    def monte_carlo_simulation(mean_returns, cov_matrix, weights, n_sim, n_days, initial_investment):
        sim_results = np.zeros((n_sim, n_days))
        for i in range(n_sim):
            daily_returns = np.random.multivariate_normal(mean_returns, cov_matrix, n_days)
            portfolio_returns = np.dot(daily_returns, weights)
            prices = initial_investment * np.cumprod(1 + portfolio_returns)
            sim_results[i, :] = prices
        return sim_results

    sim_results = monte_carlo_simulation(mean_returns, cov_matrix, weights, n_sim, n_days, initial_investment)
    sim_df = pd.DataFrame(sim_results.T, index=range(1, n_days+1))
    st.subheader("Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ Ù¾Ø±ØªÙÙˆ")
    fig2 = go.Figure()
    for i in range(min(100, n_sim)):
        fig2.add_trace(go.Scatter(x=sim_df.index, y=sim_df.iloc[:, i], line=dict(width=1), opacity=0.2, showlegend=False))
    fig2.update_layout(title="Ù¾Ø±ØªÙÙˆ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡", xaxis_title="Ø±ÙˆØ²", yaxis_title="Ø§Ø±Ø²Ø´ Ù¾Ø±ØªÙÙˆ")
    st.plotly_chart(fig2, use_container_width=True)

# --- Ù…Ø¯Ù„ VaR Ùˆ CVaR ---
if "CVaR/VaR" in selected_models and "Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ" in selected_models:
    def calculate_var_cvar(sim_results, confidence_level):
        final_values = sim_results[:, -1]
        var = np.percentile(final_values, 100 - confidence_level)
        cvar = final_values[final_values <= var].mean()
        return var, cvar

    var, cvar = calculate_var_cvar(sim_results, confidence_level)
    st.markdown(f"**Value at Risk (VaR) Ø¯Ø± Ø³Ø·Ø­ {confidence_level}%:** {var:,.0f} Ø¯Ù„Ø§Ø±")
    st.markdown(f"**Conditional Value at Risk (CVaR):** {cvar:,.0f} Ø¯Ù„Ø§Ø±")

# --- Ù…Ø¯Ù„ Married Put ---
if "Married Put" in selected_models and "Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ" in selected_models:
    st.subheader("Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù¾Ø±ØªÙÙˆ Ø¨Ø§ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Married Put")
    put_strike = (put_strike_pct / 100) * initial_investment
    sim_results_put = np.maximum(sim_results, put_strike)
    fig3 = go.Figure()
    fig3.add_trace(go.Box(y=sim_results[:, -1], name="Ù¾Ø±ØªÙÙˆ Ù…Ø¹Ù…ÙˆÙ„ÛŒ"))
    fig3.add_trace(go.Box(y=sim_results_put[:, -1], name="Married Put"))
    fig3.update_layout(title="Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø§Ø±Ø²Ø´ Ù†Ù‡Ø§ÛŒÛŒ Ù¾Ø±ØªÙÙˆ", yaxis_title="Ø§Ø±Ø²Ø´ Ù†Ù‡Ø§ÛŒÛŒ")
    st.plotly_chart(fig3, use_container_width=True)
    st.markdown(f"**Ø­Ø¯Ø§Ù‚Ù„ Ø§Ø±Ø²Ø´ Ù¾Ø±ØªÙÙˆ Ø¨Ø§ Married Put:** {put_strike:,.0f} Ø¯Ù„Ø§Ø±")

# --- Ù…Ø¯Ù„ Black-Litterman ---
if "Black-Litterman" in selected_models:
    st.subheader("Ù…Ø¯Ù„ Black-Litterman")
    # ÙØ±Ø¶: Ø¨Ø§Ø²Ø¯Ù‡ Ø¨Ø§Ø²Ø§Ø± Ø¨Ø±Ø§Ø¨Ø± Ø¨Ø§ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¨Ø§Ø²Ø¯Ù‡ Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ Ùˆ Ø±ÛŒØ³Ú© Ø¨Ø§Ø²Ø§Ø± Ø¨Ø±Ø§Ø¨Ø± Ø¨Ø§ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ÙˆØ§Ø±ÛŒØ§Ù†Ø³
    pi = mean_returns
    tau = 0.05  # Ù¾Ø§Ø±Ø§Ù…ØªØ± Ø¹Ø¯Ù… Ù‚Ø·Ø¹ÛŒØª
    P = np.eye(len(tickers))  # ÙØ±Ø¶ Ø¯ÛŒØ¯Ú¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø³ØªÙ‚Ù„
    Q = mean_returns.values.reshape(-1, 1)  # ÙØ±Ø¶ Ø¯ÛŒØ¯Ú¯Ø§Ù‡: Ø¨Ø§Ø²Ø¯Ù‡ Ù‡Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ Ø¨Ø±Ø§Ø¨Ø± Ø¨Ø§ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ØªØ§Ø±ÛŒØ®ÛŒ
    omega = np.diag(np.diag(tau * cov_matrix.values))  # Ø¹Ø¯Ù… Ù‚Ø·Ø¹ÛŒØª Ø¯ÛŒØ¯Ú¯Ø§Ù‡â€ŒÙ‡Ø§

    # ÙØ±Ù…ÙˆÙ„ Black-Litterman
    inv = np.linalg.inv(tau * cov_matrix.values)
    middle = np.linalg.inv(P.T @ np.linalg.inv(omega) @ P + inv)
    bl_mean = middle @ (inv @ pi.values.reshape(-1, 1) + P.T @ np.linalg.inv(omega) @ Q)
    bl_weights = bl_mean / np.sum(bl_mean)
    bl_weights = bl_weights.flatten()
    bl_weights_df = pd.DataFrame({"Ù†Ù…Ø§Ø¯": tickers, "ÙˆØ²Ù† Ø¨Ù‡ÛŒÙ†Ù‡": bl_weights})
    st.write("ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡ Ù¾Ø±ØªÙÙˆ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø¯Ù„ Black-Litterman:")
    st.dataframe(bl_weights_df)

# --- Ù…Ø¯Ù„ Risk Parity ---
if "Risk Parity" in selected_models:
    st.subheader("Ù…Ø¯Ù„ Risk Parity")
    # ÙˆØ§Ø±ÛŒØ§Ù†Ø³ Ù‡Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ
    asset_vols = returns.std()
    inv_vols = 1 / asset_vols
    risk_parity_weights = inv_vols / inv_vols.sum()
    rp_weights_df = pd.DataFrame({"Ù†Ù…Ø§Ø¯": tickers, "ÙˆØ²Ù† Ø¨Ù‡ÛŒÙ†Ù‡": risk_parity_weights})
    st.write("ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡ Ù¾Ø±ØªÙÙˆ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø¯Ù„ Risk Parity:")
    st.dataframe(rp_weights_df)

# --- Ù…Ø¯Ù„ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† (Random Forest) ---
if "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† (Random Forest)" in selected_models:
    st.subheader("Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø§Ø²Ø¯Ù‡ Ù¾Ø±ØªÙÙˆ Ø¨Ø§ Random Forest")
    # Ø³Ø§Ø®Øª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (lagged returns)
    features = returns.shift(1).dropna()
    target = returns.mean(axis=1).shift(-1).dropna()
    features = features.loc[target.index]
    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)
    rf = RandomForestRegressor(n_estimators=100, random_state=42)
    rf.fit(X_train, y_train)
    y_pred = rf.predict(X_test)
    st.write(f"Ø¶Ø±ÛŒØ¨ ØªØ¹ÛŒÛŒÙ† (R2) Ù…Ø¯Ù„: {rf.score(X_test, y_test):.2f}")
    pred_df = pd.DataFrame({"Ø¨Ø§Ø²Ø¯Ù‡ ÙˆØ§Ù‚Ø¹ÛŒ": y_test, "Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¯Ù„": y_pred}, index=y_test.index)
    st.line_chart(pred_df)

# --- ØªØ­Ù„ÛŒÙ„ Ø³Ù†Ø§Ø±ÛŒÙˆ Ùˆ Ø§Ø³ØªØ±Ø³ ØªØ³Øª ---
if "ØªØ­Ù„ÛŒÙ„ Ø³Ù†Ø§Ø±ÛŒÙˆ/Ø§Ø³ØªØ±Ø³ ØªØ³Øª" in selected_models:
    st.subheader("ØªØ­Ù„ÛŒÙ„ Ø³Ù†Ø§Ø±ÛŒÙˆ Ùˆ Ø§Ø³ØªØ±Ø³ ØªØ³Øª Ù¾Ø±ØªÙÙˆ")
    st.markdown("""
    Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ ØªØ§Ø«ÛŒØ± Ø´ÙˆÚ©â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø± Ø±Ø§ Ø¨Ø± Ù¾Ø±ØªÙÙˆ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ú©Ù†ÛŒØ¯.
    """)
    shock = st.slider("Ø¯Ø±ØµØ¯ Ø´ÙˆÚ© Ù…Ù†ÙÛŒ Ø¨Ù‡ Ø¨Ø§Ø²Ø¯Ù‡ Ø±ÙˆØ²Ø§Ù†Ù‡", -20, 0, -10)
    shocked_returns = returns + (shock / 100)
    shocked_portfolio = (shocked_returns @ weights).cumsum()
    normal_portfolio = (returns @ weights).cumsum()
    fig4 = go.Figure()
    fig4.add_trace(go.Scatter(x=returns.index, y=normal_portfolio, name="Ù¾Ø±ØªÙÙˆ Ø¹Ø§Ø¯ÛŒ"))
    fig4.add_trace(go.Scatter(x=returns.index, y=shocked_portfolio, name=f"Ù¾Ø±ØªÙÙˆ Ø¨Ø§ Ø´ÙˆÚ© {shock}%"))
    fig4.update_layout(title="Ø§Ø³ØªØ±Ø³ ØªØ³Øª Ù¾Ø±ØªÙÙˆ", yaxis_title="Ø¨Ø§Ø²Ø¯Ù‡ ØªØ¬Ù…Ø¹ÛŒ")
    st.plotly_chart(fig4, use_container_width=True)

# --- Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†ØªØ§ÛŒØ¬ Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ ---
if "Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ" in selected_models:
    def to_excel(df):
        output = BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            df.to_excel(writer, index=True)
        return output.getvalue()

    st.subheader("Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†ØªØ§ÛŒØ¬")
    excel_data = to_excel(sim_df)
    st.download_button("Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ù‡ Ø§Ú©Ø³Ù„", data=excel_data, file_name="sim_results.xlsx")

st.info("Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ùˆ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ø±Ø§ ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯.")
