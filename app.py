import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
import yfinance as yf
import re

from scipy.optimize import minimize
from sklearn.linear_model import LinearRegression

st.set_page_config(page_title="ØªØ­Ù„ÛŒÙ„ Ù¾Ø±ØªÙÙˆ Ø¨Ø§ Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„ÙˆØŒ CVaR Ùˆ Married Put", layout="wide")
st.title("ğŸ“Š Ø§Ø¨Ø²Ø§Ø± ØªØ­Ù„ÛŒÙ„ Ù¾Ø±ØªÙÙˆ Ø¨Ø§ Ø±ÙˆØ´ Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„ÙˆØŒ CVaRØŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ú©Ù„Ø§Ø³ÛŒÚ© Ùˆ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ")

# ===== Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ ÛŒØ§Ù‡Ùˆ ÙØ§ÛŒÙ†Ø§Ù†Ø³ =====
with st.expander("ğŸ“˜ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø§Ø² ÛŒØ§Ù‡Ùˆ ÙØ§ÛŒÙ†Ø§Ù†Ø³"):
    st.markdown("""
    <div dir="rtl" style="text-align: right; font-size: 15px">
    <b>Ù†Ø­ÙˆÙ‡ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡:</b><br>
    - Ù†Ù…Ø§Ø¯ Ù‡Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ Ø±Ø§ Ù…Ø·Ø§Ø¨Ù‚ Ø³Ø§ÛŒØª Yahoo Finance ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.<br>
    - Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø±Ø§ Ø¨Ø§ <b>Ú©Ø§Ù…Ø§</b> Ùˆ <b>Ø¨Ø¯ÙˆÙ† ÙØ§ØµÙ„Ù‡</b> ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.<br>
    - Ù…Ø«Ø§Ù„: <b>BTC-USD,AAPL,ETH-USD</b><br>
    - Ø¨Ø±Ø§ÛŒ Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ†: <b>BTC-USD</b><br>
    - Ø¨Ø±Ø§ÛŒ Ø§Ù¾Ù„: <b>AAPL</b><br>
    - Ø¨Ø±Ø§ÛŒ Ø§ØªØ±ÛŒÙˆÙ…: <b>ETH-USD</b><br>
    - Ø¨Ø±Ø§ÛŒ Ø´Ø§Ø®Øµ S&P500: <b>^GSPC</b><br>
    <br>
    <b>ØªÙˆØ¶ÛŒØ­Ø§Øª Ø¨ÛŒØ´ØªØ±:</b><br>
    - Ù†Ù…Ø§Ø¯ Ù‡Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ Ø±Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¯Ø± Ø³Ø§ÛŒØª <a href="https://finance.yahoo.com" target="_blank">Yahoo Finance</a> Ø¬Ø³ØªØ¬Ùˆ Ú©Ù†ÛŒØ¯.<br>
    - Ø§Ú¯Ø± Ú†Ù†Ø¯ Ù†Ù…Ø§Ø¯ ÙˆØ§Ø±Ø¯ Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯ØŒ ÙÙ‚Ø· Ø¨Ø§ Ú©Ø§Ù…Ø§ Ø¬Ø¯Ø§ Ú©Ù†ÛŒØ¯ Ùˆ ÙØ§ØµÙ„Ù‡ Ù†Ú¯Ø°Ø§Ø±ÛŒØ¯.<br>
    - Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯Ø´Ø¯Ù‡ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ù…Ø§Ù†Ù†Ø¯ ÙØ§ÛŒÙ„ CSV Ø¯Ø± Ø§Ø¨Ø²Ø§Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.<br>
    </div>
    """, unsafe_allow_html=True)

# =============== ØªØ§Ø¨Ø¹ Ø®ÙˆØ§Ù†Ø¯Ù† Ù…Ù‚Ø§ÙˆÙ… ÙØ§ÛŒÙ„ ===============
def smart_read_file(file):
    try:
        content = file.read()
        try:
            content = content.decode("utf-8")
        except Exception:
            content = content.decode("latin1")
        seps = [',',';','|','\t']
        sep_counts = [(s, content.count(s)) for s in seps]
        sep = max(sep_counts, key=lambda x:x[1])[0] if max(sep_counts, key=lambda x:x[1])[1] > 0 else ','
        lines = [l.strip() for l in content.splitlines() if l.strip() and not l.strip().startswith('#')]
        if not lines:
            return None
        header = [x.strip().replace('"','').replace("'",'') for x in re.split(sep, lines[0])]
        def find_col(colnames, candidates):
            for c in candidates:
                for i, h in enumerate(colnames):
                    if c.lower() in h.lower():
                        return i
            return None
        date_idx = find_col(header, ['date', 'ØªØ§Ø±ÛŒØ®'])
        price_idx = find_col(header, ['price', 'Ù‚ÛŒÙ…Øª'])
        if date_idx is None or price_idx is None:
            return None
        data_rows = []
        for row in lines[1:]:
            parts = [x.strip().replace('"','').replace("'",'') for x in re.split(sep, row)]
            if len(parts) <= max(date_idx, price_idx): continue
            date_val = parts[date_idx]
            price_val = parts[price_idx]
            price_val = price_val.replace(' ', '').replace(',', '')
            price_val = re.sub(r'[^\d\.\-]', '', price_val)
            try:
                price_float = float(price_val)
            except:
                continue
            data_rows.append([date_val, price_float])
        if not data_rows:
            return None
        df = pd.DataFrame(data_rows, columns=['Date', 'Price'])
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
        df = df.dropna(subset=['Date', 'Price'])
        df = df.sort_values('Date')
        if len(df) < 3:
            return None
        return df
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„: {e}")
        return None

# =============== Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ú©Ù„Ø§Ø³ÛŒÚ© Ùˆ Ø±Ú¯Ø±Ø³ÛŒÙˆÙ†ÛŒ ===============
def get_gmv_weights(cov_matrix):
    n = cov_matrix.shape[0]
    args = (cov_matrix,)
    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1.0})
    bounds = tuple((0, 1) for _ in range(n))
    result = minimize(lambda w, cov: w.T @ cov @ w, n*[1./n], args=args, method='SLSQP', bounds=bounds, constraints=constraints)
    return result.x

def get_max_sharpe_weights(mean_returns, cov_matrix, rf=0):
    n = len(mean_returns)
    def neg_sharpe(w, mean, cov, rf):
        port_return = np.dot(w, mean)
        port_vol = np.sqrt(np.dot(w.T, np.dot(cov, w)))
        return -(port_return - rf) / port_vol
    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1.0})
    bounds = tuple((0, 1) for _ in range(n))
    result = minimize(neg_sharpe, n*[1./n], args=(mean_returns, cov_matrix, rf), method='SLSQP', bounds=bounds, constraints=constraints)
    return result.x

def regression_forecast(prices, periods_ahead=1):
    prices = prices.dropna()
    if len(prices) < 10:
        return np.nan
    X = np.arange(len(prices)).reshape(-1, 1)
    y = prices.values
    model = LinearRegression().fit(X, y)
    pred = model.predict([[len(prices) + periods_ahead - 1]])
    return float(pred)

# =============== Ø³Ø§ÛŒØ¯Ø¨Ø§Ø± ===============
st.sidebar.header("ğŸ“‚ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ (CSV ÛŒØ§ TXT)")
uploaded_files = st.sidebar.file_uploader(
    "Ú†Ù†Ø¯ ÙØ§ÛŒÙ„ CSV ÛŒØ§ TXT Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ (Ù‡Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ ÛŒÚ© ÙØ§ÛŒÙ„)", type=['csv', 'txt'], accept_multiple_files=True, key="uploader"
)

period = st.sidebar.selectbox("Ø¨Ø§Ø²Ù‡ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø¯Ù‡", ['Ù…Ø§Ù‡Ø§Ù†Ù‡', 'Ø³Ù‡â€ŒÙ…Ø§Ù‡Ù‡', 'Ø´Ø´â€ŒÙ…Ø§Ù‡Ù‡'])
resample_rule = {'Ù…Ø§Ù‡Ø§Ù†Ù‡': 'M', 'Ø³Ù‡â€ŒÙ…Ø§Ù‡Ù‡': 'Q', 'Ø´Ø´â€ŒÙ…Ø§Ù‡Ù‡': '2Q'}[period]
annual_factor = {'Ù…Ø§Ù‡Ø§Ù†Ù‡': 12, 'Ø³Ù‡â€ŒÙ…Ø§Ù‡Ù‡': 4, 'Ø´Ø´â€ŒÙ…Ø§Ù‡Ù‡': 2}[period]
user_risk = st.sidebar.slider("Ø±ÛŒØ³Ú© Ù‡Ø¯Ù Ù¾Ø±ØªÙÙˆ (Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÛŒØ§Ø± Ø³Ø§Ù„Ø§Ù†Ù‡)", 0.01, 1.0, 0.25, 0.01)
cvar_alpha = st.sidebar.slider("Ø³Ø·Ø­ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† CVaR", 0.80, 0.99, 0.95, 0.01)

with st.sidebar.expander("ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø§Ø¯Ù‡ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø§Ø² ÛŒØ§Ù‡Ùˆ ÙØ§ÛŒÙ†Ø§Ù†Ø³"):
    st.markdown("""
    <div dir="rtl" style="text-align: right; font-size: 14px">
    <b>Ø±Ø§Ù‡Ù†Ù…Ø§:</b><br>
    - Ù†Ù…Ø§Ø¯ Ù‡Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ Ø±Ø§ Ù…Ø·Ø§Ø¨Ù‚ Ø³Ø§ÛŒØª ÛŒØ§Ù‡Ùˆ ÙØ§ÛŒÙ†Ø§Ù†Ø³ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.<br>
    - Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø±Ø§ Ø¨Ø§ Ú©Ø§Ù…Ø§ Ùˆ Ø¨Ø¯ÙˆÙ† ÙØ§ØµÙ„Ù‡ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.<br>
    - Ù…Ø«Ø§Ù„: <b>BTC-USD,AAPL,GOOGL,ETH-USD</b><br>
    - Ø¨Ø±Ø§ÛŒ Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ†: <b>BTC-USD</b> <br>
    - Ø¨Ø±Ø§ÛŒ Ø§Ù¾Ù„: <b>AAPL</b> <br>
    - Ø¨Ø±Ø§ÛŒ Ø§ØªØ±ÛŒÙˆÙ…: <b>ETH-USD</b> <br>
    - Ø¨Ø±Ø§ÛŒ Ø´Ø§Ø®Øµ S&P500: <b>^GSPC</b> <br>
    </div>
    """, unsafe_allow_html=True)
    tickers_input = st.text_input("Ù†Ù…Ø§Ø¯ Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ (Ø¨Ø§ Ú©Ø§Ù…Ø§ Ùˆ Ø¨Ø¯ÙˆÙ† ÙØ§ØµÙ„Ù‡)")
    start = st.date_input("ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹", value=pd.to_datetime("2023-01-01"))
    end = st.date_input("ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†", value=pd.to_datetime("today"))
    download_btn = st.button("Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø¢Ù†Ù„Ø§ÛŒÙ†")

downloaded_dfs = []
if download_btn and tickers_input.strip():
    tickers = [t.strip() for t in tickers_input.strip().split(",") if t.strip()]
    try:
        data = yf.download(tickers, start=start, end=end, progress=False, group_by='ticker', auto_adjust=True)
        if not data.empty:
            for t in tickers:
                if len(tickers) == 1:
                    df = data.reset_index()[['Date', 'Close']].rename(columns={'Close': 'Price'})
                else:
                    if t in data.columns.levels[0]:
                        df_t = data[t].reset_index()[['Date', 'Close']].rename(columns={'Close': 'Price'})
                        df = df_t
                    else:
                        st.warning(f"Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯ {t} Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                        continue
                df['Date'] = pd.to_datetime(df['Date'])
                downloaded_dfs.append((t, df))
                st.success(f"Ø¯Ø§Ø¯Ù‡ {t} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯.")
        else:
            st.error("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯!")
    except Exception as ex:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡: {ex}")

if downloaded_dfs:
    st.markdown('<div dir="rtl" style="text-align: right;"><b>Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯Ø´Ø¯Ù‡ Ø§Ø² ÛŒØ§Ù‡Ùˆ ÙØ§ÛŒÙ†Ø§Ù†Ø³:</b></div>', unsafe_allow_html=True)
    for t, df in downloaded_dfs:
        st.markdown(f"<div dir='rtl' style='text-align: right;'><b>{t}</b></div>", unsafe_allow_html=True)
        st.dataframe(df.head())

if uploaded_files or downloaded_dfs:
    prices_df = pd.DataFrame()
    asset_names = []
    insured_assets = {}

    # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯Ø´Ø¯Ù‡
    for t, df in downloaded_dfs:
        name = t
        if 'Date' not in df.columns or 'Price' not in df.columns:
            st.warning(f"Ø¯Ø§Ø¯Ù‡ Ø¢Ù†Ù„Ø§ÛŒÙ† {name} Ø¨Ø§ÛŒØ¯ Ø¯Ø§Ø±Ø§ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ 'Date' Ùˆ 'Price' Ø¨Ø§Ø´Ø¯.")
            continue
        df = df.dropna(subset=['Date', 'Price'])
        df = df[['Date', 'Price']].set_index('Date')
        df.columns = [name]
        prices_df = df if prices_df.empty else prices_df.join(df, how='inner')
        asset_names.append(name)

    # ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ÛŒ Ú©Ø§Ø±Ø¨Ø± (Ù‡ÙˆØ´Ù…Ù†Ø¯)
    for file in uploaded_files:
        df = smart_read_file(file)
        if df is None:
            st.warning(f"ÙØ§ÛŒÙ„ {file.name} Ø¨Ø§ÛŒØ¯ Ø­Ø¯Ø§Ù‚Ù„ Ø³Ù‡ Ø³Ø·Ø± Ø¯Ø§Ø¯Ù‡ Ø³Ø§Ù„Ù… Ùˆ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ 'Date' Ùˆ 'Price' Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯.")
            continue
        name = file.name.split('.')[0]
        df = df[['Date', 'Price']].set_index('Date')
        df.columns = [name]
        prices_df = df if prices_df.empty else prices_df.join(df, how='inner')
        asset_names.append(name)

        st.sidebar.markdown(f"---\n### âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨ÛŒÙ…Ù‡ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø±Ø§ÛŒÛŒ: `{name}`")
        insured = st.sidebar.checkbox(f"ğŸ“Œ ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¨ÛŒÙ…Ù‡ Ø¨Ø±Ø§ÛŒ {name}", key=f"insured_{name}")
        if insured:
            loss_percent = st.sidebar.number_input(f"ğŸ“‰ Ø¯Ø±ØµØ¯ Ø¶Ø±Ø± Ù…Ø¹Ø§Ù…Ù„Ù‡ Ù¾ÙˆØª Ø¨Ø±Ø§ÛŒ {name}", 0.0, 100.0, 30.0, step=0.01, key=f"loss_{name}")
            strike = st.sidebar.number_input(f"ğŸ¯ Ù‚ÛŒÙ…Øª Ø§Ø¹Ù…Ø§Ù„ Ù¾ÙˆØª Ø¨Ø±Ø§ÛŒ {name}", 0.0, 1e6, 100.0, step=0.01, key=f"strike_{name}")
            premium = st.sidebar.number_input(f"ğŸ’° Ù‚ÛŒÙ…Øª Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ù¾ÙˆØª Ø¨Ø±Ø§ÛŒ {name}", 0.0, 1e6, 5.0, step=0.01, key=f"premium_{name}")
            amount = st.sidebar.number_input(f"ğŸ“¦ Ù…Ù‚Ø¯Ø§Ø± Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ø¨Ø±Ø§ÛŒ {name}", 0.0, 1e6, 1.0, step=0.01, key=f"amount_{name}")
            spot_price = st.sidebar.number_input(f"ğŸ“Œ Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ Ø¯Ø§Ø±Ø§ÛŒÛŒ Ù¾Ø§ÛŒÙ‡ {name}", 0.0, 1e6, 100.0, step=0.01, key=f"spot_{name}")
            asset_amount = st.sidebar.number_input(f"ğŸ“¦ Ù…Ù‚Ø¯Ø§Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ Ù¾Ø§ÛŒÙ‡ {name}", 0.0, 1e6, 1.0, step=0.01, key=f"base_{name}")
            insured_assets[name] = {
                'loss_percent': loss_percent,
                'strike': strike,
                'premium': premium,
                'amount': amount,
                'spot': spot_price,
                'base': asset_amount
            }

    if prices_df.empty:
        st.error("âŒ Ø¯Ø§Ø¯Ù‡â€ŒÛŒ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        st.stop()

    st.subheader("ğŸ§ª Ù¾ÛŒØ´â€ŒÙ†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§")
    st.dataframe(prices_df.tail())

    resampled_prices = prices_df.resample(resample_rule).last().dropna()
    returns = resampled_prices.pct_change().dropna()
    mean_returns = returns.mean() * annual_factor
    cov_matrix = returns.cov() * annual_factor
    std_devs = np.sqrt(np.diag(cov_matrix))

    adjusted_cov = cov_matrix.copy()
    preference_weights = []

    for i, name in enumerate(asset_names):
        if name in insured_assets:
            risk_scale = 1 - insured_assets[name]['loss_percent'] / 100
            adjusted_cov.iloc[i, :] *= risk_scale
            adjusted_cov.iloc[:, i] *= risk_scale
            preference_weights.append(1 / (std_devs[i] * risk_scale**0.7))  # ÙˆØ²Ù† Ø¨ÛŒØ´ØªØ± Ø¯Ø± Ø¨ÛŒÙ…Ù‡
        else:
            preference_weights.append(1 / std_devs[i])
    preference_weights = np.array(preference_weights)
    preference_weights /= np.sum(preference_weights)

    n_portfolios = 10000
    n_mc = 1000
    results = np.zeros((5 + len(asset_names), n_portfolios))
    np.random.seed(42)
    rf = 0

    downside = returns.copy()
    downside[downside > 0] = 0

    for i in range(n_portfolios):
        weights = np.random.random(len(asset_names)) * preference_weights
        weights /= np.sum(weights)
        port_return = np.dot(weights, mean_returns)
        port_std = np.sqrt(np.dot(weights.T, np.dot(adjusted_cov, weights)))
        downside_risk = np.sqrt(np.dot(weights.T, np.dot(downside.cov() * annual_factor, weights)))
        sharpe_ratio = (port_return - rf) / port_std
        sortino_ratio = (port_return - rf) / downside_risk if downside_risk > 0 else np.nan

        mc_sims = np.random.multivariate_normal(mean_returns/annual_factor, adjusted_cov/annual_factor, n_mc)
        port_mc_returns = np.dot(mc_sims, weights)
        VaR = np.percentile(port_mc_returns, (1 - cvar_alpha) * 100)
        CVaR = port_mc_returns[port_mc_returns <= VaR].mean() if np.any(port_mc_returns <= VaR) else VaR

        results[0, i] = port_return
        results[1, i] = port_std
        results[2, i] = sharpe_ratio
        results[3, i] = sortino_ratio
        results[4, i] = -CVaR
        results[5:, i] = weights

    best_idx = np.argmin(np.abs(results[1] - user_risk))
    best_return = results[0, best_idx]
    best_risk = results[1, best_idx]
    best_sharpe = results[2, best_idx]
    best_sortino = results[3, best_idx]
    best_weights = results[5:, best_idx]

    best_cvar_idx = np.argmin(results[4])
    best_cvar_return = results[0, best_cvar_idx]
    best_cvar_risk = results[1, best_cvar_idx]
    best_cvar_cvar = results[4, best_cvar_idx]
    best_cvar_weights = results[5:, best_cvar_idx]

    # ============ Ù…Ø¯Ù„ Ú©Ù„Ø§Ø³ÛŒÚ© Ùˆ Ø±Ú¯Ø±Ø³ÛŒÙˆÙ†ÛŒ/Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ============
    with st.expander("ğŸ¤– Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ú©Ù„Ø§Ø³ÛŒÚ© Ùˆ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†/Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"):
        st.markdown("""
        <div dir="rtl" style="text-align: right">
        <b>Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù¾Ø±ØªÙÙˆ Ø±Ø§ Ø¨Ø§ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ú©Ù„Ø§Ø³ÛŒÚ© Ùˆ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ØªØ­Ù„ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯:</b><br>
        <ul>
        <li><b>Ø­Ø¯Ø§Ù‚Ù„ ÙˆØ§Ø±ÛŒØ§Ù†Ø³ Ø¬Ù‡Ø§Ù†ÛŒ (GMV):</b> Ú©Ù…â€ŒØ±ÛŒØ³Ú©â€ŒØªØ±ÛŒÙ† ØªØ±Ú©ÛŒØ¨ Ù…Ù…Ú©Ù† Ù¾Ø±ØªÙÙˆØŒ ØµØ±ÙØ§Ù‹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ø§Ù‡Ø´ Ù†ÙˆØ³Ø§Ù†.</li>
        <li><b>Ù…Ø§Ú©Ø²ÛŒÙ…Ù… Ù†Ø±Ø® Ø´Ø§Ø±Ù¾ (MSR):</b> Ø¨Ù‡ØªØ±ÛŒÙ† ØªØ±Ú©ÛŒØ¨ Ø¨Ø§Ø²Ø¯Ù‡ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ø±ÛŒØ³Ú©.</li>
        <li><b>Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø±Ú¯Ø±Ø³ÛŒÙˆÙ†ÛŒ:</b> Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‚ÛŒÙ…Øª Ø¢ÛŒÙ†Ø¯Ù‡ Ù‡Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ Ø¨Ø§ Ø³Ø§Ø¯Ù‡â€ŒØªØ±ÛŒÙ† Ù…Ø¯Ù„ ML (Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ø®Ø·ÛŒ).</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)

        # GMV
        gmv_weights = get_gmv_weights(cov_matrix)
        gmv_ret = np.dot(gmv_weights, mean_returns)
        gmv_risk = np.sqrt(np.dot(gmv_weights.T, np.dot(cov_matrix, gmv_weights)))
        st.markdown("#### ğŸŸ¦ Ø­Ø¯Ø§Ù‚Ù„ ÙˆØ§Ø±ÛŒØ§Ù†Ø³ Ø¬Ù‡Ø§Ù†ÛŒ (GMV)")
        st.markdown(f'''
        <div dir="rtl" style="text-align: right">
        Ø¯Ø± Ø§ÛŒÙ† Ù…Ø¯Ù„ØŒ ÙˆØ²Ù† Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ Ø·ÙˆØ±ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ú©Ù‡ ÙˆØ§Ø±ÛŒØ§Ù†Ø³ (Ù†ÙˆØ³Ø§Ù†) Ù¾Ø±ØªÙÙˆ Ø­Ø¯Ø§Ù‚Ù„ Ø´ÙˆØ¯. Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ø§ÙØ±Ø§Ø¯ Ø±ÛŒØ³Ú©â€ŒÚ¯Ø±ÛŒØ².<br>
        <b>Ø¨Ø§Ø²Ø¯Ù‡ Ø³Ø§Ù„Ø§Ù†Ù‡ Ù¾Ø±ØªÙÙˆ:</b> {gmv_ret:.2%}<br>
        <b>Ø±ÛŒØ³Ú© Ø³Ø§Ù„Ø§Ù†Ù‡ Ù¾Ø±ØªÙÙˆ:</b> {gmv_risk:.2%}<br>
        {'<br>'.join([f"ğŸ”¹ <b>{asset_names[i]}</b>: {w*100:.2f}%" for i, w in enumerate(gmv_weights)])}
        </div>
        ''', unsafe_allow_html=True)

        fig_gmv = go.Figure(data=[go.Pie(labels=asset_names, values=gmv_weights*100, hole=0.5)])
        fig_gmv.update_layout(title="ØªØ±Ú©ÛŒØ¨ ÙˆØ²Ù†ÛŒ Ù¾Ø±ØªÙÙˆ GMV")
        st.plotly_chart(fig_gmv, use_container_width=True)

        # Max Sharpe
        ms_weights = get_max_sharpe_weights(mean_returns, cov_matrix)
        ms_ret = np.dot(ms_weights, mean_returns)
        ms_risk = np.sqrt(np.dot(ms_weights.T, np.dot(cov_matrix, ms_weights)))
        ms_sharpe = (ms_ret - rf) / ms_risk
        st.markdown("#### ğŸŸ§ Ù¾Ø±ØªÙÙˆ Ø¨Ø§ Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† Ù†Ø±Ø® Ø´Ø§Ø±Ù¾ (MSR)")
        st.markdown(f'''
        <div dir="rtl" style="text-align: right">
        Ø§ÛŒÙ† Ù…Ø¯Ù„ Ù¾Ø±ØªÙÙˆ Ø¨Ø§ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ù†Ø³Ø¨Øª Ø¨Ø§Ø²Ø¯Ù‡ Ø¨Ù‡ Ø±ÛŒØ³Ú© (Sharpe) Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ø§ÙØ±Ø§Ø¯ÛŒ Ú©Ù‡ Ø¨Ù‡ Ø¯Ù†Ø¨Ø§Ù„ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø¨Ù‡Ø±Ù‡â€ŒÙˆØ±ÛŒ Ø±ÛŒØ³Ú© Ù‡Ø³ØªÙ†Ø¯.<br>
        <b>Ø¨Ø§Ø²Ø¯Ù‡ Ø³Ø§Ù„Ø§Ù†Ù‡ Ù¾Ø±ØªÙÙˆ:</b> {ms_ret:.2%}<br>
        <b>Ø±ÛŒØ³Ú© Ø³Ø§Ù„Ø§Ù†Ù‡ Ù¾Ø±ØªÙÙˆ:</b> {ms_risk:.2%}<br>
        <b>Ù†Ø³Ø¨Øª Ø´Ø§Ø±Ù¾:</b> {ms_sharpe:.2f}<br>
        {'<br>'.join([f"ğŸ”¸ <b>{asset_names[i]}</b>: {w*100:.2f}%" for i, w in enumerate(ms_weights)])}
        </div>
        ''', unsafe_allow_html=True)

        fig_ms = go.Figure(data=[go.Pie(labels=asset_names, values=ms_weights*100, hole=0.5)])
        fig_ms.update_layout(title="ØªØ±Ú©ÛŒØ¨ ÙˆØ²Ù†ÛŒ Ù¾Ø±ØªÙÙˆ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø´Ø§Ø±Ù¾")
        st.plotly_chart(fig_ms, use_container_width=True)

        # Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ø®Ø·ÛŒ
        st.markdown("#### ğŸŸ© Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø±Ú¯Ø±Ø³ÛŒÙˆÙ†ÛŒ Ø¨Ø§Ø²Ø¯Ù‡ Ø¢ÛŒÙ†Ø¯Ù‡ Ù‡Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ (ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†)")
        st.markdown('''
        <div dir="rtl" style="text-align: right">
        Ø¨Ø§ Ù…Ø¯Ù„ Ø±Ú¯Ø±Ø³ÛŒÙˆÙ† Ø®Ø·ÛŒ (Ø³Ø§Ø¯Ù‡â€ŒØªØ±ÛŒÙ† Ù…Ø¯Ù„ ML)ØŒ Ø±ÙˆÙ†Ø¯ Ù‚ÛŒÙ…Øª Ù‡Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ Ø¯Ø± Ø¢ÛŒÙ†Ø¯Ù‡ Ù†Ø²Ø¯ÛŒÚ© Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯ (Ù…Ø«Ù„Ø§Ù‹ Ù…Ø§Ù‡ Ø¢ÛŒÙ†Ø¯Ù‡). Ù‡Ø±Ú†Ù†Ø¯ Ø§ÛŒÙ† Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ Ù‚Ø·Ø¹ÛŒØª Ù†Ø¯Ø§Ø±Ù†Ø¯ØŒ Ø§Ù…Ø§ Ø¨Ø±Ø§ÛŒ ØªØ®Ù…ÛŒÙ† Ø±ÙˆÙ†Ø¯ Ùˆ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø§ÙˆÙ„ÛŒÙ‡ Ù…ÙÛŒØ¯ Ø§Ø³Øª.
        </div>''', unsafe_allow_html=True)
        reg_rows = []
        for name in asset_names:
            last_price = resampled_prices[name].dropna()
            reg_pred = regression_forecast(last_price, periods_ahead=1)
            delta = reg_pred - last_price.iloc[-1] if not np.isnan(reg_pred) else np.nan
            reg_rows.append({
                "Ø¯Ø§Ø±Ø§ÛŒÛŒ": name,
                "Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ": last_price.iloc[-1],
                "Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±Ú¯Ø±Ø³ÛŒÙˆÙ†ÛŒ Ù…Ø§Ù‡ Ø¨Ø¹Ø¯": reg_pred,
                "ØªØºÛŒÛŒØ± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ": delta
            })
        reg_df = pd.DataFrame(reg_rows)
        st.dataframe(reg_df.set_index("Ø¯Ø§Ø±Ø§ÛŒÛŒ"), use_container_width=True)
        st.markdown('''
        <div dir="rtl" style="text-align: right;">
        Ø§ÛŒÙ† Ø¬Ø¯ÙˆÙ„ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‚ÛŒÙ…Øª Ø±Ú¯Ø±Ø³ÛŒÙˆÙ†ÛŒ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯. Ø³ØªÙˆÙ† "ØªØºÛŒÛŒØ± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ" Ù…ÛŒØ²Ø§Ù† Ø±Ø´Ø¯ ÛŒØ§ Ú©Ø§Ù‡Ø´ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ Ø±Ø§ Ø¨Ø±Ø¢ÙˆØ±Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        </div>
        ''', unsafe_allow_html=True)

    # === Ø§Ø¯Ø§Ù…Ù‡ Ú©Ø¯ Ø§ØµÙ„ÛŒ (Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„ÙˆØŒ CVaRØŒ Married PutØŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ØªØµØ§Ø¯ÙÛŒØŒ ...)

    # ... (Ù‡Ù…Ø§Ù† Ú©Ø¯ Ø®Ø±ÙˆØ¬ÛŒ Ù‚Ø¨Ù„ÛŒ ØªÙˆ Ø§Ø² Ø§ÛŒÙ†Ø¬Ø§ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯ - Ù‡ÛŒÚ† ØªØºÛŒÛŒØ±ÛŒ Ø¯Ø± ÙÛŒÚ†Ø±Ù‡Ø§ Ù†Ø¯Ø§Ø¯Ù‡â€ŒØ§Ù…)

    # ----- Ø¨Ù‚ÛŒÙ‡ Ú©Ø¯ Ø§Ø¨Ø²Ø§Ø± ØªÙˆ Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ø§Ù‚ÛŒ Ø¨Ù…Ø§Ù†Ø¯ -----
    # (Ø§Ø² st.subheader("ğŸ“Š Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø®Ù„Ø§ØµÙ‡ Ù¾Ø±ØªÙÙˆ") ØªØ§ Ø§Ù†ØªÙ‡Ø§ Ù‡ÛŒÚ† ØªØºÛŒÛŒØ±ÛŒ Ù†Ø¯Ù‡ØŒ ÙÙ‚Ø· Ø§ÛŒÙ† expander Ø¬Ø¯ÛŒØ¯ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯)
else:
    st.warning("âš ï¸ Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSV Ø´Ø§Ù…Ù„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Date Ùˆ Price Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ø§Ø² Ø¨Ø®Ø´ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø¯Ø§Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.")
