import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import re
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from io import BytesIO
from lightgbm import LGBMRegressor
from xgboost import XGBRegressor

st.set_page_config(page_title="ØªØ­Ù„ÛŒÙ„ Ù¾Ø±ØªÙÙˆ (Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú†Ù†Ø¯ ÙØ§ÛŒÙ„ Ø¯Ø§Ø¯Ù‡)", layout="wide")
st.title("ğŸ“Š Ø§Ø¨Ø²Ø§Ø± ØªØ­Ù„ÛŒÙ„ Ù¾Ø±ØªÙÙˆ (Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú†Ù†Ø¯ ÙØ§ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ ØªØ§Ø±ÛŒØ®ÛŒ)")

with st.expander("ğŸ“˜ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡"):
    st.markdown("""
    - Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ú†Ù†Ø¯ÛŒÙ† ÙØ§ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ (CSV ÛŒØ§ TXT) Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯.
    - Ù‡Ø± ÙØ§ÛŒÙ„ Ø¨Ø§ÛŒØ¯ Ø´Ø§Ù…Ù„ ØªØ§Ø±ÛŒØ® Ùˆ Ù‚ÛŒÙ…Øª Ø¯Ø§Ø±Ø§ÛŒÛŒ Ø¨Ø§Ø´Ø¯ (Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒÛŒ Ù…Ø«Ù„ date, price, close, adj close Ùˆ ...).
    - Ø§Ø¨Ø²Ø§Ø± Ø¨Ù‡ Ø·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± Ù†Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø±Ø§ ØªÙ…ÛŒØ² Ùˆ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù‚Øµ Ø±Ø§ Ø­Ø°Ù Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Ù‡Ù…Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø± ÛŒÚ© Ø¬Ø¯ÙˆÙ„ ØªØ±Ú©ÛŒØ¨ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    - Ù†Ø§Ù… Ù‡Ø± Ù†Ù…Ø§Ø¯ Ø§Ø² Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ú¯Ø±ÙØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ (Ù…Ø«Ù„Ø§Ù‹ AAPL.csv).
    """)

uploaded_files = st.file_uploader("ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡ Ù¾Ø±ØªÙÙˆ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯ (CSV ÛŒØ§ TXT)", type=["csv", "txt"], accept_multiple_files=True)
if not uploaded_files:
    st.warning("Ù„Ø·ÙØ§Ù‹ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© ÙØ§ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯.")
    st.stop()

def clean_columns(columns):
    return [re.sub(r'[^a-zA-Z0-9]', '', str(col)).lower() for col in columns]

def auto_detect_price_column(cols):
    price_keywords = ['price', 'close', 'adjclose', 'adj_close', 'last']
    for col in cols:
        for key in price_keywords:
            if key in col:
                return col
    return None

all_data = []

for file in uploaded_files:
    # Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„
    try:
        df = pd.read_csv(file)
    except:
        df = pd.read_csv(file, delimiter="\t")
    df.columns = clean_columns(df.columns)
    df = df.dropna(axis=1, how='all').dropna(axis=0, how='all')
    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø³ØªÙˆÙ† ØªØ§Ø±ÛŒØ® Ùˆ Ù‚ÛŒÙ…Øª
    date_col = None
    for col in df.columns:
        if 'date' in col or 'data' in col or 'time' in col:
            date_col = col
            break
    price_col = auto_detect_price_column(df.columns)
    if date_col is None or price_col is None:
        st.error(f"Ø³ØªÙˆÙ† ØªØ§Ø±ÛŒØ® ÛŒØ§ Ù‚ÛŒÙ…Øª Ø¯Ø± ÙØ§ÛŒÙ„ {file.name} Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
        st.stop()
    df = df[[date_col, price_col]].dropna()
    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
    df = df.dropna(subset=[date_col])
    df = df.sort_values(by=date_col).reset_index(drop=True)
    # Ù†Ø§Ù… Ù†Ù…Ø§Ø¯ Ø±Ø§ Ø§Ø² Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†
    symbol = file.name.split('.')[0]
    df = df.rename(columns={price_col: symbol, date_col: 'date'})
    all_data.append(df.set_index('date'))

# Ø§Ø¯ØºØ§Ù… Ù‡Ù…Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ§Ø±ÛŒØ®
final_df = pd.concat(all_data, axis=1)
final_df = final_df.dropna(how='all')  # Ø­Ø°Ù Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ù‡Ù…Ù‡ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø®Ø§Ù„ÛŒâ€ŒØ§Ù†Ø¯
final_df = final_df.sort_index()

st.subheader("Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ±Ú©ÛŒØ¨â€ŒØ´Ø¯Ù‡ Ùˆ ØªÙ…ÛŒØ²Ø´Ø¯Ù‡:")
st.dataframe(final_df)

tickers = list(final_df.columns)
st.sidebar.header("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾Ø±ØªÙÙˆ")
weights_input = st.sidebar.text_area(
    "ÙˆØ²Ù† Ù¾Ø±ØªÙÙˆ (Ø¨Ø§ ÙˆÛŒØ±Ú¯ÙˆÙ„ Ø¬Ø¯Ø§ Ú©Ù†ÛŒØ¯ØŒ Ù…Ø¬Ù…ÙˆØ¹=1)",
    value=",".join([str(round(1/len(tickers), 2))]*len(tickers))
)
try:
    weights = [float(w.strip()) for w in weights_input.split(",") if w.strip()]
    assert len(tickers) == len(weights), "ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…Ø§Ø¯Ù‡Ø§ Ùˆ ÙˆØ²Ù†â€ŒÙ‡Ø§ Ø¨Ø±Ø§Ø¨Ø± Ù†ÛŒØ³Øª."
    assert np.isclose(sum(weights), 1.0), "Ù…Ø¬Ù…ÙˆØ¹ ÙˆØ²Ù†â€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Û± Ø¨Ø§Ø´Ø¯."
except Exception as e:
    st.error(f"Ø®Ø·Ø§ Ø¯Ø± ÙˆØ±ÙˆØ¯ÛŒ: {e}")
    st.stop()

n_sim = st.sidebar.number_input("ØªØ¹Ø¯Ø§Ø¯ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ", 100, 5000, 1000)
n_days = st.sidebar.number_input("ØªØ¹Ø¯Ø§Ø¯ Ø±ÙˆØ²Ù‡Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ", 30, 365, 180)
confidence_level = st.sidebar.slider("Ø³Ø·Ø­ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† VaR/CVaR", 90, 99, 95)
initial_investment = st.sidebar.number_input("Ø³Ø±Ù…Ø§ÛŒÙ‡ Ø§ÙˆÙ„ÛŒÙ‡ (Ø¯Ù„Ø§Ø±)", 1000, 1000000, 10000)
put_strike_pct = st.sidebar.slider("Ø¯Ø±ØµØ¯ Ù‚ÛŒÙ…Øª Ø§Ø¹Ù…Ø§Ù„ Ø§Ø®ØªÛŒØ§Ø± ÙØ±ÙˆØ´ (Married Put)", 70, 100, 90)

model_options = [
    "Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ",
    "CVaR/VaR",
    "Married Put",
    "Black-Litterman",
    "Risk Parity",
    "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† (Random Forest)",
    "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† (LightGBM)",
    "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† (XGBoost)",
    "ØªØ­Ù„ÛŒÙ„ Ø³Ù†Ø§Ø±ÛŒÙˆ/Ø§Ø³ØªØ±Ø³ ØªØ³Øª"
]
selected_models = st.sidebar.multiselect("Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡", model_options, default=model_options[:3])

returns = final_df.pct_change().dropna()
mean_returns = returns.mean()
cov_matrix = returns.cov()

st.subheader("Ù†Ù…ÙˆØ¯Ø§Ø± Ù‚ÛŒÙ…Øª Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§")
fig = go.Figure()
for t in final_df.columns:
    fig.add_trace(go.Scatter(x=final_df.index, y=final_df[t], name=t))
st.plotly_chart(fig, use_container_width=True)

# Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ
if "Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ" in selected_models:
    def monte_carlo_simulation(mean_returns, cov_matrix, weights, n_sim, n_days, initial_investment):
        sim_results = np.zeros((n_sim, n_days))
        for i in range(n_sim):
            daily_returns = np.random.multivariate_normal(mean_returns, cov_matrix, n_days)
            portfolio_returns = np.dot(daily_returns, weights)
            prices = initial_investment * np.cumprod(1 + portfolio_returns)
            sim_results[i, :] = prices
        return sim_results

    sim_results = monte_carlo_simulation(mean_returns, cov_matrix, weights, n_sim, n_days, initial_investment)
    sim_df = pd.DataFrame(sim_results.T, index=range(1, n_days+1))
    st.subheader("Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ Ù¾Ø±ØªÙÙˆ")
    fig2 = go.Figure()
    for i in range(min(100, n_sim)):
        fig2.add_trace(go.Scatter(x=sim_df.index, y=sim_df.iloc[:, i], line=dict(width=1), opacity=0.2, showlegend=False))
    fig2.update_layout(title="Ù¾Ø±ØªÙÙˆ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡", xaxis_title="Ø±ÙˆØ²", yaxis_title="Ø§Ø±Ø²Ø´ Ù¾Ø±ØªÙÙˆ")
    st.plotly_chart(fig2, use_container_width=True)

if "CVaR/VaR" in selected_models and "Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ" in selected_models:
    def calculate_var_cvar(sim_results, confidence_level):
        final_values = sim_results[:, -1]
        var = np.percentile(final_values, 100 - confidence_level)
        cvar = final_values[final_values <= var].mean()
        return var, cvar

    var, cvar = calculate_var_cvar(sim_results, confidence_level)
    st.markdown(f"**Value at Risk (VaR) Ø¯Ø± Ø³Ø·Ø­ {confidence_level}%:** {var:,.0f} Ø¯Ù„Ø§Ø±")
    st.markdown(f"**Conditional Value at Risk (CVaR):** {cvar:,.0f} Ø¯Ù„Ø§Ø±")

if "Married Put" in selected_models and "Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ" in selected_models:
    st.subheader("Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù¾Ø±ØªÙÙˆ Ø¨Ø§ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Married Put")
    put_strike = (put_strike_pct / 100) * initial_investment
    sim_results_put = np.maximum(sim_results, put_strike)
    fig3 = go.Figure()
    fig3.add_trace(go.Box(y=sim_results[:, -1], name="Ù¾Ø±ØªÙÙˆ Ù…Ø¹Ù…ÙˆÙ„ÛŒ"))
    fig3.add_trace(go.Box(y=sim_results_put[:, -1], name="Married Put"))
    fig3.update_layout(title="Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø§Ø±Ø²Ø´ Ù†Ù‡Ø§ÛŒÛŒ Ù¾Ø±ØªÙÙˆ", yaxis_title="Ø§Ø±Ø²Ø´ Ù†Ù‡Ø§ÛŒÛŒ")
    st.plotly_chart(fig3, use_container_width=True)
    st.markdown(f"**Ø­Ø¯Ø§Ù‚Ù„ Ø§Ø±Ø²Ø´ Ù¾Ø±ØªÙÙˆ Ø¨Ø§ Married Put:** {put_strike:,.0f} Ø¯Ù„Ø§Ø±")

if "Black-Litterman" in selected_models:
    st.subheader("Ù…Ø¯Ù„ Black-Litterman")
    pi = mean_returns
    tau = 0.05
    P = np.eye(len(final_df.columns))
    Q = mean_returns.values.reshape(-1, 1)
    omega = np.diag(np.diag(tau * cov_matrix.values))
    inv = np.linalg.inv(tau * cov_matrix.values)
    middle = np.linalg.inv(P.T @ np.linalg.inv(omega) @ P + inv)
    bl_mean = middle @ (inv @ pi.values.reshape(-1, 1) + P.T @ np.linalg.inv(omega) @ Q)
    bl_weights = bl_mean / np.sum(bl_mean)
    bl_weights = bl_weights.flatten()
    bl_weights_df = pd.DataFrame({"Ù†Ù…Ø§Ø¯": final_df.columns, "ÙˆØ²Ù† Ø¨Ù‡ÛŒÙ†Ù‡": bl_weights})
    st.write("ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡ Ù¾Ø±ØªÙÙˆ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø¯Ù„ Black-Litterman:")
    st.dataframe(bl_weights_df)

if "Risk Parity" in selected_models:
    st.subheader("Ù…Ø¯Ù„ Risk Parity")
    asset_vols = returns.std()
    inv_vols = 1 / asset_vols
    risk_parity_weights = inv_vols / inv_vols.sum()
    rp_weights_df = pd.DataFrame({"Ù†Ù…Ø§Ø¯": final_df.columns, "ÙˆØ²Ù† Ø¨Ù‡ÛŒÙ†Ù‡": risk_parity_weights})
    st.write("ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡ Ù¾Ø±ØªÙÙˆ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø¯Ù„ Risk Parity:")
    st.dataframe(rp_weights_df)

def ml_feature_engineering(returns):
    features = returns.shift(1).dropna()
    target = returns.mean(axis=1).shift(-1).dropna()
    features = features.loc[target.index]
    return features, target

if "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† (Random Forest)" in selected_models:
    st.subheader("Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø§Ø²Ø¯Ù‡ Ù¾Ø±ØªÙÙˆ Ø¨Ø§ Random Forest")
    features, target = ml_feature_engineering(returns)
    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)
    rf = RandomForestRegressor(n_estimators=100, random_state=42)
    rf.fit(X_train, y_train)
    y_pred = rf.predict(X_test)
    st.write(f"Ø¶Ø±ÛŒØ¨ ØªØ¹ÛŒÛŒÙ† (R2) Ù…Ø¯Ù„: {rf.score(X_test, y_test):.2f}")
    pred_df = pd.DataFrame({"Ø¨Ø§Ø²Ø¯Ù‡ ÙˆØ§Ù‚Ø¹ÛŒ": y_test, "Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¯Ù„": y_pred}, index=y_test.index)
    st.line_chart(pred_df)

if "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† (LightGBM)" in selected_models:
    st.subheader("Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø§Ø²Ø¯Ù‡ Ù¾Ø±ØªÙÙˆ Ø¨Ø§ LightGBM")
    features, target = ml_feature_engineering(returns)
    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)
    lgbm = LGBMRegressor(n_estimators=100, random_state=42)
    lgbm.fit(X_train, y_train)
    y_pred = lgbm.predict(X_test)
    st.write(f"Ø¶Ø±ÛŒØ¨ ØªØ¹ÛŒÛŒÙ† (R2) Ù…Ø¯Ù„: {lgbm.score(X_test, y_test):.2f}")
    pred_df = pd.DataFrame({"Ø¨Ø§Ø²Ø¯Ù‡ ÙˆØ§Ù‚Ø¹ÛŒ": y_test, "Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¯Ù„": y_pred}, index=y_test.index)
    st.line_chart(pred_df)

if "ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† (XGBoost)" in selected_models:
    st.subheader("Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø§Ø²Ø¯Ù‡ Ù¾Ø±ØªÙÙˆ Ø¨Ø§ XGBoost")
    features, target = ml_feature_engineering(returns)
    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)
    xgb = XGBRegressor(n_estimators=100, random_state=42)
    xgb.fit(X_train, y_train)
    y_pred = xgb.predict(X_test)
    st.write(f"Ø¶Ø±ÛŒØ¨ ØªØ¹ÛŒÛŒÙ† (R2) Ù…Ø¯Ù„: {xgb.score(X_test, y_test):.2f}")
    pred_df = pd.DataFrame({"Ø¨Ø§Ø²Ø¯Ù‡ ÙˆØ§Ù‚Ø¹ÛŒ": y_test, "Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¯Ù„": y_pred}, index=y_test.index)
    st.line_chart(pred_df)

if "ØªØ­Ù„ÛŒÙ„ Ø³Ù†Ø§Ø±ÛŒÙˆ/Ø§Ø³ØªØ±Ø³ ØªØ³Øª" in selected_models:
    st.subheader("ØªØ­Ù„ÛŒÙ„ Ø³Ù†Ø§Ø±ÛŒÙˆ Ùˆ Ø§Ø³ØªØ±Ø³ ØªØ³Øª Ù¾Ø±ØªÙÙˆ")
    st.markdown("""
    Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ ØªØ§Ø«ÛŒØ± Ø´ÙˆÚ©â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø± Ø±Ø§ Ø¨Ø± Ù¾Ø±ØªÙÙˆ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ú©Ù†ÛŒØ¯.
    """)
    shock = st.slider("Ø¯Ø±ØµØ¯ Ø´ÙˆÚ© Ù…Ù†ÙÛŒ Ø¨Ù‡ Ø¨Ø§Ø²Ø¯Ù‡ Ø±ÙˆØ²Ø§Ù†Ù‡", -20, 0, -10)
    shocked_returns = returns + (shock / 100)
    shocked_portfolio = (shocked_returns @ weights).cumsum()
    normal_portfolio = (returns @ weights).cumsum()
    fig4 = go.Figure()
    fig4.add_trace(go.Scatter(x=returns.index, y=normal_portfolio, name="Ù¾Ø±ØªÙÙˆ Ø¹Ø§Ø¯ÛŒ"))
    fig4.add_trace(go.Scatter(x=returns.index, y=shocked_portfolio, name=f"Ù¾Ø±ØªÙÙˆ Ø¨Ø§ Ø´ÙˆÚ© {shock}%"))
    fig4.update_layout(title="Ø§Ø³ØªØ±Ø³ ØªØ³Øª Ù¾Ø±ØªÙÙˆ", yaxis_title="Ø¨Ø§Ø²Ø¯Ù‡ ØªØ¬Ù…Ø¹ÛŒ")
    st.plotly_chart(fig4, use_container_width=True)

if "Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ" in selected_models:
    def to_excel(df):
        output = BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            df.to_excel(writer, index=True)
        return output.getvalue()

    st.subheader("Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†ØªØ§ÛŒØ¬")
    excel_data = to_excel(sim_df)
    st.download_button("Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ù‡ Ø§Ú©Ø³Ù„", data=excel_data, file_name="sim_results.xlsx")

st.info("Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ùˆ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ø±Ø§ ØªØºÛŒÛŒØ± Ø¯Ù‡ÛŒØ¯.")
